{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grocery-categories-v06-b.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chuan137/egohands/blob/master/grocery/grocery_categories_v06_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yo3Q73Saai1",
        "colab_type": "text"
      },
      "source": [
        "## Note\n",
        "\n",
        "__Description__ more categories for training.\n",
        "\n",
        "__Update__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qqone641roL",
        "colab_type": "text"
      },
      "source": [
        "## Training Details\n",
        "\n",
        "**Train data**\n",
        "* 3 categories: BEANS, CAKE, CANDY, MILK, PASTA \n",
        "* image size 224\n",
        "* \\# training set 568\n",
        "* \\# validation set 67\n",
        "\n",
        "**Architecture**\n",
        "* **Without** fully connected layer\n",
        "* prediction layer with L2 regularizer\n",
        "\n",
        "**Hyper parameters**\n",
        "* softmax layer with regularizer, weight = 0.0001\n",
        "* optimizer Adam, learning rate 0.0001\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I2iCuFUaYLN",
        "colab_type": "text"
      },
      "source": [
        "## Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItuoQ_0d5DRX",
        "colab_type": "code",
        "outputId": "3e4d6113-fc3b-4e9e-f0d4-a3e07bda4cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTbsckzr5_Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp /content/drive/My\\ Drive/freiburg_groceries_dataset.zip .\n",
        "!unzip -q freiburg_groceries_dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr5Ug_gW_Z66",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIGaFb0tEYrk",
        "colab_type": "code",
        "outputId": "0470c335-8628-493e-c113-82d661539cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFq1ZV6gSOqa",
        "colab_type": "text"
      },
      "source": [
        "* split train and test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C5jWZ8-MwsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def find_images(dpath, subdir=''):\n",
        "    \"\"\" return [](filepath, label) \"\"\"\n",
        "    images = []\n",
        "    if os.path.isdir(os.path.join(dpath, subdir)):\n",
        "        for filename in os.listdir(os.path.join(dpath, subdir)):\n",
        "            filepath = os.path.join(subdir, filename)\n",
        "            images.append(filepath)\n",
        "    return images\n",
        "\n",
        "\n",
        "def split_images(images, splits):\n",
        "    'shuffle and split images[] to train[], validation and test[]'\n",
        "    if type(splits) not in (list, tuple):\n",
        "        raise TypeError(\"splits must be list or tuple\")\n",
        "    elif abs(sum(splits) - 1.0) > 0.000001:\n",
        "        raise ValueError(\"sum of splits should be 1.0\")\n",
        "    elif len(splits) not in (2, 3):\n",
        "        raise ValueError(\"splits should have 2 or 3 elements\") \n",
        "    random.shuffle(images)\n",
        "    n = len(images)\n",
        "    if len(splits) == 2:\n",
        "        n1, _ = [round(x*n) for x in splits]\n",
        "        print(n1)\n",
        "        return images[:n1], images[n1:]\n",
        "    else:\n",
        "        n1, n2, _ = [round(x*n) for x in splits]\n",
        "        return images[:n1], images[n1:n1+n2], images[n1+n2:]\n",
        "\n",
        "all_classes = next(os.walk('images'))[1]\n",
        "\n",
        "train = []\n",
        "val = []\n",
        "test = []\n",
        "splits = (0.8, 0.1, 0.1)\n",
        "for cl in all_classes:\n",
        "    images = find_images('images', cl)\n",
        "    tr, v, te = split_images(images, splits)\n",
        "    train += zip(tr, [cl] * len(tr))\n",
        "    val += zip(v, [cl] * len(v))\n",
        "    test += zip(te, [cl] * len(te))\n",
        "\n",
        "train_df = pd.DataFrame(train, columns=['filename', 'class'])\n",
        "val_df = pd.DataFrame(val, columns=['filename', 'class'])\n",
        "test_df = pd.DataFrame(test, columns=['filename', 'class'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O_UWuRoSnj0",
        "colab_type": "text"
      },
      "source": [
        "* create data generator for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw24dpUCSUO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "seed = 76\n",
        "\n",
        "classes = ['BEANS', 'CAKE', 'CANDY', 'MILK', 'PASTA']\n",
        "n_classes = len(classes)\n",
        "classmap = {c: i for i, c in enumerate(classes)}\n",
        "img_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrYHwVzR94Fm",
        "colab_type": "code",
        "outputId": "e068b1d3-a651-4d1a-a3b8-c4ee05e2c70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import os\n",
        "labels_count = dict()\n",
        "for img_class in classes:\n",
        "    labels_count[img_class] = len(os.listdir('images/' + img_class))\n",
        "total_count = sum(labels_count.values())\n",
        "class_weights = {cls: total_count / count for cls, count in \n",
        "                 enumerate(labels_count.values())}\n",
        "class_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 7.375,\n",
              " 1: 6.229813664596273,\n",
              " 2: 2.696236559139785,\n",
              " 3: 6.191358024691358,\n",
              " 4: 5.8313953488372094}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFpsYrRS68GA",
        "colab_type": "code",
        "outputId": "a56817de-4743-4dd1-8885-fb931dc1227e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dataset = train_df[train_df['class'].isin(classes)]\n",
        "train_filenames = train_dataset['filename'].tolist()\n",
        "train_labels = train_dataset['class'].tolist()\n",
        "train_labels = [classmap[l] for l in train_labels]\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=n_classes)\n",
        "\n",
        "val_dataset = val_df[val_df['class'].isin(classes)]\n",
        "val_filenames = val_dataset['filename'].tolist()\n",
        "val_labels = val_dataset['class'].tolist()\n",
        "val_labels = [classmap[l] for l in val_labels]\n",
        "val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=n_classes)\n",
        "\n",
        "test_dataset = test_df[test_df['class'].isin(classes)]\n",
        "test_filenames = test_dataset['filename'].tolist()\n",
        "test_labels = test_dataset['class'].tolist()\n",
        "test_labels = [classmap[l] for l in test_labels]\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=n_classes)\n",
        "\n",
        "len(train_filenames), len(val_filenames), len(test_filenames)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(804, 100, 99)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3PqYoYVyf1A",
        "colab_type": "code",
        "outputId": "b9cb6f4e-44e8-4d8f-fcd6-cb0825a7a92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Function to load and preprocess each image\n",
        "def _parse_fn(filename, label):\n",
        "    filename = 'images/' + filename\n",
        "    img = tf.io.read_file(filename)\n",
        "    img = tf.image.decode_png(img)\n",
        "    img = (tf.cast(img, tf.float32)/127.5) - 1\n",
        "    # img = tf.cast(img, tf.float32)/255.0\n",
        "    img = tf.image.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "    return img, label\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.constant(train_filenames), tf.constant(train_labels))\n",
        ")\n",
        "\n",
        "val_data = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.constant(val_filenames), tf.constant(val_labels))\n",
        ")\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.constant(test_filenames), tf.constant(test_labels))\n",
        ")\n",
        "\n",
        "train_data = (train_data.shuffle(buffer_size=len(train_filenames))\n",
        "             .map(_parse_fn)\n",
        "             .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "val_data = (val_data.shuffle(buffer_size=len(val_filenames))\n",
        "            .map(_parse_fn)\n",
        "            .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "test_data = (test_data.map(_parse_fn))\n",
        "\n",
        "n_train = len(train_filenames)\n",
        "n_val = len(val_filenames)\n",
        "n_train, n_val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(804, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EJEDFP7Xmwh",
        "colab_type": "text"
      },
      "source": [
        " * build train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTM4GivYeRAq",
        "colab_type": "code",
        "outputId": "906842a5-36ed-462b-9bd1-37076b2a1bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "w_l2 = 0.0001\n",
        "\n",
        "# Pre-trained model with MobileNetV2\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=img_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze the pre-trained model weights\n",
        "base_model.trainable = False\n",
        "\n",
        "# Trainable classification head\n",
        "maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
        "fc_layer_1 = tf.keras.layers.Dense(1280, activation='relu')\n",
        "\n",
        "# Prediction with L2 regularizer\n",
        "prediction_layer = tf.keras.layers.Dense(\n",
        "    n_classes, \n",
        "    kernel_regularizer=regularizers.l2(w_l2), \n",
        "    activation='softmax')\n",
        "\n",
        "# Layer classification head with feature detector\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    maxpool_layer,\n",
        "    # fc_layer_1,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 6405      \n",
            "=================================================================\n",
            "Total params: 2,264,389\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwcS-hJ-eSe9",
        "colab_type": "code",
        "outputId": "3fab4c17-449a-4c13-a582-5d6bdf44afb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 1000\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        ")\n",
        "\n",
        "steps_per_epoch = round(n_train/BATCH_SIZE)\n",
        "validation_steps = round(n_val/BATCH_SIZE)\n",
        "\n",
        "hist = model.fit(train_data.repeat(), \n",
        "                 epochs=epochs,\n",
        "                 steps_per_epoch=steps_per_epoch,\n",
        "                 validation_data=val_data.repeat(),\n",
        "                 validation_steps=validation_steps,\n",
        "                 class_weight=class_weights)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 25 steps, validate for 3 steps\n",
            "Epoch 1/1000\n",
            "25/25 [==============================] - 13s 521ms/step - loss: 5.3386 - accuracy: 0.2188 - val_loss: 3.6751 - val_accuracy: 0.2500\n",
            "Epoch 2/1000\n",
            "25/25 [==============================] - 6s 221ms/step - loss: 3.8023 - accuracy: 0.2565 - val_loss: 3.5827 - val_accuracy: 0.2396\n",
            "Epoch 3/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 3.5408 - accuracy: 0.2733 - val_loss: 3.3726 - val_accuracy: 0.2604\n",
            "Epoch 4/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 3.4298 - accuracy: 0.2902 - val_loss: 3.1379 - val_accuracy: 0.2708\n",
            "Epoch 5/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 3.0616 - accuracy: 0.3096 - val_loss: 2.9222 - val_accuracy: 0.2917\n",
            "Epoch 6/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 2.8534 - accuracy: 0.3368 - val_loss: 2.9008 - val_accuracy: 0.2812\n",
            "Epoch 7/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 2.8184 - accuracy: 0.3549 - val_loss: 2.6696 - val_accuracy: 0.3333\n",
            "Epoch 8/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 2.3780 - accuracy: 0.4041 - val_loss: 2.6395 - val_accuracy: 0.3438\n",
            "Epoch 9/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 2.3560 - accuracy: 0.3769 - val_loss: 2.5572 - val_accuracy: 0.3542\n",
            "Epoch 10/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 2.2102 - accuracy: 0.4301 - val_loss: 2.3993 - val_accuracy: 0.3750\n",
            "Epoch 11/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 2.1637 - accuracy: 0.4560 - val_loss: 2.3357 - val_accuracy: 0.3854\n",
            "Epoch 12/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 1.8706 - accuracy: 0.4909 - val_loss: 2.1950 - val_accuracy: 0.3958\n",
            "Epoch 13/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 1.9815 - accuracy: 0.4573 - val_loss: 2.1561 - val_accuracy: 0.4062\n",
            "Epoch 14/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 1.6997 - accuracy: 0.5220 - val_loss: 2.1170 - val_accuracy: 0.4688\n",
            "Epoch 15/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 1.7944 - accuracy: 0.5194 - val_loss: 2.0835 - val_accuracy: 0.4583\n",
            "Epoch 16/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 1.4653 - accuracy: 0.5466 - val_loss: 2.1193 - val_accuracy: 0.4479\n",
            "Epoch 17/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 1.5302 - accuracy: 0.5725 - val_loss: 1.7778 - val_accuracy: 0.4896\n",
            "Epoch 18/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 1.5007 - accuracy: 0.5583 - val_loss: 2.0205 - val_accuracy: 0.4583\n",
            "Epoch 19/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 1.3194 - accuracy: 0.6205 - val_loss: 1.9143 - val_accuracy: 0.4583\n",
            "Epoch 20/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 1.3648 - accuracy: 0.5881 - val_loss: 1.7158 - val_accuracy: 0.4896\n",
            "Epoch 21/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 1.3102 - accuracy: 0.6075 - val_loss: 1.8275 - val_accuracy: 0.4583\n",
            "Epoch 22/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 1.2187 - accuracy: 0.6438 - val_loss: 1.8441 - val_accuracy: 0.5104\n",
            "Epoch 23/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 1.3662 - accuracy: 0.6321 - val_loss: 1.8261 - val_accuracy: 0.4896\n",
            "Epoch 24/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 1.2474 - accuracy: 0.6464 - val_loss: 1.6469 - val_accuracy: 0.5208\n",
            "Epoch 25/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 1.1026 - accuracy: 0.6567 - val_loss: 1.6913 - val_accuracy: 0.5521\n",
            "Epoch 26/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 1.0689 - accuracy: 0.6684 - val_loss: 1.6902 - val_accuracy: 0.5417\n",
            "Epoch 27/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 1.0545 - accuracy: 0.6775 - val_loss: 1.5726 - val_accuracy: 0.5729\n",
            "Epoch 28/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.9885 - accuracy: 0.7060 - val_loss: 1.4888 - val_accuracy: 0.5521\n",
            "Epoch 29/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.9679 - accuracy: 0.6995 - val_loss: 1.5171 - val_accuracy: 0.5729\n",
            "Epoch 30/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.9558 - accuracy: 0.7060 - val_loss: 1.5076 - val_accuracy: 0.5938\n",
            "Epoch 31/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.8820 - accuracy: 0.7034 - val_loss: 1.4839 - val_accuracy: 0.6146\n",
            "Epoch 32/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.9108 - accuracy: 0.7293 - val_loss: 1.4840 - val_accuracy: 0.5833\n",
            "Epoch 33/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.8760 - accuracy: 0.7448 - val_loss: 1.5889 - val_accuracy: 0.5833\n",
            "Epoch 34/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.9640 - accuracy: 0.7047 - val_loss: 1.4614 - val_accuracy: 0.6250\n",
            "Epoch 35/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.9809 - accuracy: 0.7111 - val_loss: 1.4047 - val_accuracy: 0.6042\n",
            "Epoch 36/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.7967 - accuracy: 0.7267 - val_loss: 1.4332 - val_accuracy: 0.6042\n",
            "Epoch 37/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.7166 - accuracy: 0.7526 - val_loss: 1.3547 - val_accuracy: 0.6562\n",
            "Epoch 38/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.8498 - accuracy: 0.7422 - val_loss: 1.4232 - val_accuracy: 0.5833\n",
            "Epoch 39/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.8033 - accuracy: 0.7513 - val_loss: 1.4381 - val_accuracy: 0.6354\n",
            "Epoch 40/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.6887 - accuracy: 0.7746 - val_loss: 1.1804 - val_accuracy: 0.6458\n",
            "Epoch 41/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.7845 - accuracy: 0.7487 - val_loss: 1.4598 - val_accuracy: 0.6250\n",
            "Epoch 42/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.7231 - accuracy: 0.7837 - val_loss: 1.4341 - val_accuracy: 0.5729\n",
            "Epoch 43/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.7495 - accuracy: 0.7642 - val_loss: 1.2009 - val_accuracy: 0.6771\n",
            "Epoch 44/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.7029 - accuracy: 0.7746 - val_loss: 1.2918 - val_accuracy: 0.6771\n",
            "Epoch 45/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.6870 - accuracy: 0.7915 - val_loss: 1.2652 - val_accuracy: 0.6562\n",
            "Epoch 46/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.7405 - accuracy: 0.7837 - val_loss: 1.3633 - val_accuracy: 0.5938\n",
            "Epoch 47/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.6496 - accuracy: 0.7915 - val_loss: 1.1935 - val_accuracy: 0.6771\n",
            "Epoch 48/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.6748 - accuracy: 0.7655 - val_loss: 1.2058 - val_accuracy: 0.6875\n",
            "Epoch 49/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.5699 - accuracy: 0.7979 - val_loss: 1.2831 - val_accuracy: 0.6458\n",
            "Epoch 50/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.5253 - accuracy: 0.8225 - val_loss: 1.2499 - val_accuracy: 0.6667\n",
            "Epoch 51/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.5941 - accuracy: 0.8199 - val_loss: 1.2250 - val_accuracy: 0.6771\n",
            "Epoch 52/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.7112 - accuracy: 0.8199 - val_loss: 1.1863 - val_accuracy: 0.6667\n",
            "Epoch 53/1000\n",
            "25/25 [==============================] - 5s 213ms/step - loss: 0.5505 - accuracy: 0.8150 - val_loss: 1.1669 - val_accuracy: 0.6667\n",
            "Epoch 54/1000\n",
            "25/25 [==============================] - 5s 211ms/step - loss: 0.5378 - accuracy: 0.8199 - val_loss: 1.2152 - val_accuracy: 0.6771\n",
            "Epoch 55/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.5142 - accuracy: 0.8109 - val_loss: 1.1797 - val_accuracy: 0.6667\n",
            "Epoch 56/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.4738 - accuracy: 0.8290 - val_loss: 1.2450 - val_accuracy: 0.6458\n",
            "Epoch 57/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.4872 - accuracy: 0.8225 - val_loss: 1.0916 - val_accuracy: 0.6667\n",
            "Epoch 58/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.5052 - accuracy: 0.8407 - val_loss: 1.1346 - val_accuracy: 0.6667\n",
            "Epoch 59/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.5058 - accuracy: 0.8368 - val_loss: 1.1078 - val_accuracy: 0.6771\n",
            "Epoch 60/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.5229 - accuracy: 0.8238 - val_loss: 1.1967 - val_accuracy: 0.6562\n",
            "Epoch 61/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.4791 - accuracy: 0.8277 - val_loss: 1.0820 - val_accuracy: 0.6771\n",
            "Epoch 62/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.3779 - accuracy: 0.8523 - val_loss: 1.1776 - val_accuracy: 0.6562\n",
            "Epoch 63/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.4316 - accuracy: 0.8562 - val_loss: 1.0486 - val_accuracy: 0.6771\n",
            "Epoch 64/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.4872 - accuracy: 0.8238 - val_loss: 0.9603 - val_accuracy: 0.6875\n",
            "Epoch 65/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.4402 - accuracy: 0.8536 - val_loss: 1.2426 - val_accuracy: 0.6458\n",
            "Epoch 66/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.5581 - accuracy: 0.8277 - val_loss: 1.1144 - val_accuracy: 0.6667\n",
            "Epoch 67/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.4917 - accuracy: 0.8212 - val_loss: 0.8968 - val_accuracy: 0.6875\n",
            "Epoch 68/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.5622 - accuracy: 0.8316 - val_loss: 1.1776 - val_accuracy: 0.6354\n",
            "Epoch 69/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.4480 - accuracy: 0.8614 - val_loss: 1.1335 - val_accuracy: 0.6667\n",
            "Epoch 70/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.4809 - accuracy: 0.8575 - val_loss: 1.1646 - val_accuracy: 0.6458\n",
            "Epoch 71/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.4402 - accuracy: 0.8394 - val_loss: 1.0423 - val_accuracy: 0.6771\n",
            "Epoch 72/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.4522 - accuracy: 0.8446 - val_loss: 1.0156 - val_accuracy: 0.6562\n",
            "Epoch 73/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.4266 - accuracy: 0.8744 - val_loss: 1.3426 - val_accuracy: 0.6458\n",
            "Epoch 74/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.4151 - accuracy: 0.8523 - val_loss: 1.0787 - val_accuracy: 0.6667\n",
            "Epoch 75/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.3551 - accuracy: 0.8718 - val_loss: 1.1453 - val_accuracy: 0.6562\n",
            "Epoch 76/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.3840 - accuracy: 0.8536 - val_loss: 1.0353 - val_accuracy: 0.6771\n",
            "Epoch 77/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.4145 - accuracy: 0.8692 - val_loss: 1.1317 - val_accuracy: 0.6458\n",
            "Epoch 78/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.3219 - accuracy: 0.8718 - val_loss: 1.0768 - val_accuracy: 0.6562\n",
            "Epoch 79/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.3675 - accuracy: 0.8537 - val_loss: 1.0896 - val_accuracy: 0.6562\n",
            "Epoch 80/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.4107 - accuracy: 0.8562 - val_loss: 1.0983 - val_accuracy: 0.6667\n",
            "Epoch 81/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.3486 - accuracy: 0.8795 - val_loss: 0.9412 - val_accuracy: 0.6667\n",
            "Epoch 82/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.4111 - accuracy: 0.8536 - val_loss: 0.8500 - val_accuracy: 0.6875\n",
            "Epoch 83/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.2854 - accuracy: 0.8938 - val_loss: 0.9964 - val_accuracy: 0.6667\n",
            "Epoch 84/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.3080 - accuracy: 0.8744 - val_loss: 0.9414 - val_accuracy: 0.7083\n",
            "Epoch 85/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.3732 - accuracy: 0.8705 - val_loss: 1.0768 - val_accuracy: 0.6562\n",
            "Epoch 86/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.3253 - accuracy: 0.8847 - val_loss: 1.1808 - val_accuracy: 0.6458\n",
            "Epoch 87/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.3169 - accuracy: 0.8808 - val_loss: 1.0090 - val_accuracy: 0.6667\n",
            "Epoch 88/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.3015 - accuracy: 0.8951 - val_loss: 1.0843 - val_accuracy: 0.6562\n",
            "Epoch 89/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.4028 - accuracy: 0.8795 - val_loss: 1.0901 - val_accuracy: 0.6875\n",
            "Epoch 90/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.2883 - accuracy: 0.9132 - val_loss: 0.9773 - val_accuracy: 0.6875\n",
            "Epoch 91/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.4043 - accuracy: 0.8860 - val_loss: 1.1693 - val_accuracy: 0.6667\n",
            "Epoch 92/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.3425 - accuracy: 0.8899 - val_loss: 0.8944 - val_accuracy: 0.6979\n",
            "Epoch 93/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.2689 - accuracy: 0.8899 - val_loss: 0.9640 - val_accuracy: 0.6875\n",
            "Epoch 94/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.3774 - accuracy: 0.8808 - val_loss: 1.0122 - val_accuracy: 0.6771\n",
            "Epoch 95/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.3155 - accuracy: 0.9106 - val_loss: 1.2274 - val_accuracy: 0.6667\n",
            "Epoch 96/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.3139 - accuracy: 0.8756 - val_loss: 0.9368 - val_accuracy: 0.6771\n",
            "Epoch 97/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.3186 - accuracy: 0.8964 - val_loss: 1.1723 - val_accuracy: 0.6562\n",
            "Epoch 98/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.3489 - accuracy: 0.8860 - val_loss: 1.0644 - val_accuracy: 0.6562\n",
            "Epoch 99/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.2888 - accuracy: 0.8951 - val_loss: 0.9485 - val_accuracy: 0.6667\n",
            "Epoch 100/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.2812 - accuracy: 0.8964 - val_loss: 0.9876 - val_accuracy: 0.6771\n",
            "Epoch 101/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.2907 - accuracy: 0.8912 - val_loss: 1.0671 - val_accuracy: 0.6771\n",
            "Epoch 102/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.2818 - accuracy: 0.8951 - val_loss: 0.9110 - val_accuracy: 0.6771\n",
            "Epoch 103/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.2660 - accuracy: 0.9093 - val_loss: 0.9693 - val_accuracy: 0.6771\n",
            "Epoch 104/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.3726 - accuracy: 0.8886 - val_loss: 1.0201 - val_accuracy: 0.6667\n",
            "Epoch 105/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.2791 - accuracy: 0.9013 - val_loss: 0.9861 - val_accuracy: 0.7083\n",
            "Epoch 106/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.2554 - accuracy: 0.8990 - val_loss: 1.0227 - val_accuracy: 0.6562\n",
            "Epoch 107/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2593 - accuracy: 0.9067 - val_loss: 1.0193 - val_accuracy: 0.6667\n",
            "Epoch 108/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.2241 - accuracy: 0.9184 - val_loss: 0.9772 - val_accuracy: 0.6875\n",
            "Epoch 109/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.2539 - accuracy: 0.9106 - val_loss: 0.9083 - val_accuracy: 0.6771\n",
            "Epoch 110/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.4381 - accuracy: 0.9041 - val_loss: 1.1204 - val_accuracy: 0.6771\n",
            "Epoch 111/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.2100 - accuracy: 0.9275 - val_loss: 0.9656 - val_accuracy: 0.6771\n",
            "Epoch 112/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.3002 - accuracy: 0.9145 - val_loss: 1.0003 - val_accuracy: 0.6667\n",
            "Epoch 113/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.3015 - accuracy: 0.9171 - val_loss: 0.8635 - val_accuracy: 0.6667\n",
            "Epoch 114/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1962 - accuracy: 0.9249 - val_loss: 0.9785 - val_accuracy: 0.6562\n",
            "Epoch 115/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.2038 - accuracy: 0.9236 - val_loss: 0.9703 - val_accuracy: 0.6667\n",
            "Epoch 116/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2503 - accuracy: 0.9210 - val_loss: 1.0371 - val_accuracy: 0.6354\n",
            "Epoch 117/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.2403 - accuracy: 0.9028 - val_loss: 1.0426 - val_accuracy: 0.7083\n",
            "Epoch 118/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.3154 - accuracy: 0.9119 - val_loss: 0.8874 - val_accuracy: 0.6667\n",
            "Epoch 119/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.3599 - accuracy: 0.9262 - val_loss: 0.9069 - val_accuracy: 0.6979\n",
            "Epoch 120/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.2374 - accuracy: 0.9171 - val_loss: 1.0615 - val_accuracy: 0.6875\n",
            "Epoch 121/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.2330 - accuracy: 0.9158 - val_loss: 0.9797 - val_accuracy: 0.6667\n",
            "Epoch 122/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.2306 - accuracy: 0.9145 - val_loss: 0.8893 - val_accuracy: 0.6875\n",
            "Epoch 123/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.2721 - accuracy: 0.9197 - val_loss: 1.1606 - val_accuracy: 0.6979\n",
            "Epoch 124/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1986 - accuracy: 0.9301 - val_loss: 0.8771 - val_accuracy: 0.6771\n",
            "Epoch 125/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.2246 - accuracy: 0.9132 - val_loss: 0.9255 - val_accuracy: 0.6875\n",
            "Epoch 126/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2272 - accuracy: 0.9132 - val_loss: 0.9474 - val_accuracy: 0.6771\n",
            "Epoch 127/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1809 - accuracy: 0.9288 - val_loss: 0.9506 - val_accuracy: 0.6979\n",
            "Epoch 128/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.3538 - accuracy: 0.8951 - val_loss: 0.9863 - val_accuracy: 0.6458\n",
            "Epoch 129/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.4104 - accuracy: 0.9028 - val_loss: 0.8373 - val_accuracy: 0.7188\n",
            "Epoch 130/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.2163 - accuracy: 0.9223 - val_loss: 0.7905 - val_accuracy: 0.7083\n",
            "Epoch 131/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.1921 - accuracy: 0.9250 - val_loss: 0.9382 - val_accuracy: 0.6771\n",
            "Epoch 132/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.2082 - accuracy: 0.9249 - val_loss: 0.9160 - val_accuracy: 0.6667\n",
            "Epoch 133/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.3775 - accuracy: 0.9106 - val_loss: 0.9125 - val_accuracy: 0.6667\n",
            "Epoch 134/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.2161 - accuracy: 0.9301 - val_loss: 0.9345 - val_accuracy: 0.6979\n",
            "Epoch 135/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1883 - accuracy: 0.9249 - val_loss: 0.7962 - val_accuracy: 0.6875\n",
            "Epoch 136/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.2063 - accuracy: 0.9171 - val_loss: 1.0175 - val_accuracy: 0.6979\n",
            "Epoch 137/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1465 - accuracy: 0.9508 - val_loss: 0.8962 - val_accuracy: 0.6875\n",
            "Epoch 138/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1560 - accuracy: 0.9417 - val_loss: 0.7752 - val_accuracy: 0.6979\n",
            "Epoch 139/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.2469 - accuracy: 0.9288 - val_loss: 1.0404 - val_accuracy: 0.6771\n",
            "Epoch 140/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1789 - accuracy: 0.9456 - val_loss: 0.9108 - val_accuracy: 0.6771\n",
            "Epoch 141/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.2953 - accuracy: 0.9119 - val_loss: 1.0711 - val_accuracy: 0.6979\n",
            "Epoch 142/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.2545 - accuracy: 0.9365 - val_loss: 0.8424 - val_accuracy: 0.7083\n",
            "Epoch 143/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.2132 - accuracy: 0.9378 - val_loss: 0.9859 - val_accuracy: 0.7188\n",
            "Epoch 144/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.3085 - accuracy: 0.9236 - val_loss: 0.9472 - val_accuracy: 0.7188\n",
            "Epoch 145/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1771 - accuracy: 0.9417 - val_loss: 0.9518 - val_accuracy: 0.6979\n",
            "Epoch 146/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.2016 - accuracy: 0.9404 - val_loss: 0.8139 - val_accuracy: 0.6979\n",
            "Epoch 147/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1915 - accuracy: 0.9404 - val_loss: 0.8595 - val_accuracy: 0.6979\n",
            "Epoch 148/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1383 - accuracy: 0.9560 - val_loss: 0.9739 - val_accuracy: 0.7083\n",
            "Epoch 149/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.2138 - accuracy: 0.9352 - val_loss: 1.0491 - val_accuracy: 0.6875\n",
            "Epoch 150/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1474 - accuracy: 0.9417 - val_loss: 0.8437 - val_accuracy: 0.7188\n",
            "Epoch 151/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1916 - accuracy: 0.9339 - val_loss: 0.8969 - val_accuracy: 0.7083\n",
            "Epoch 152/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.2226 - accuracy: 0.9443 - val_loss: 0.8335 - val_accuracy: 0.6875\n",
            "Epoch 153/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1408 - accuracy: 0.9547 - val_loss: 0.9897 - val_accuracy: 0.7083\n",
            "Epoch 154/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2473 - accuracy: 0.9301 - val_loss: 1.0472 - val_accuracy: 0.6458\n",
            "Epoch 155/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.1932 - accuracy: 0.9288 - val_loss: 0.8675 - val_accuracy: 0.6979\n",
            "Epoch 156/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1316 - accuracy: 0.9573 - val_loss: 0.8797 - val_accuracy: 0.6875\n",
            "Epoch 157/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.1879 - accuracy: 0.9325 - val_loss: 1.0251 - val_accuracy: 0.6771\n",
            "Epoch 158/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1698 - accuracy: 0.9378 - val_loss: 0.8749 - val_accuracy: 0.6979\n",
            "Epoch 159/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1856 - accuracy: 0.9365 - val_loss: 0.8853 - val_accuracy: 0.7083\n",
            "Epoch 160/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1407 - accuracy: 0.9443 - val_loss: 0.9336 - val_accuracy: 0.6979\n",
            "Epoch 161/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1765 - accuracy: 0.9443 - val_loss: 0.7947 - val_accuracy: 0.7188\n",
            "Epoch 162/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1703 - accuracy: 0.9495 - val_loss: 0.7992 - val_accuracy: 0.7292\n",
            "Epoch 163/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1763 - accuracy: 0.9521 - val_loss: 0.9185 - val_accuracy: 0.6979\n",
            "Epoch 164/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.2685 - accuracy: 0.9404 - val_loss: 0.8051 - val_accuracy: 0.7083\n",
            "Epoch 165/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1385 - accuracy: 0.9560 - val_loss: 0.8389 - val_accuracy: 0.7292\n",
            "Epoch 166/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.2118 - accuracy: 0.9339 - val_loss: 1.0563 - val_accuracy: 0.6667\n",
            "Epoch 167/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2091 - accuracy: 0.9417 - val_loss: 0.7960 - val_accuracy: 0.7292\n",
            "Epoch 168/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1641 - accuracy: 0.9417 - val_loss: 0.8157 - val_accuracy: 0.7083\n",
            "Epoch 169/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1546 - accuracy: 0.9534 - val_loss: 1.0064 - val_accuracy: 0.7083\n",
            "Epoch 170/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.2727 - accuracy: 0.9508 - val_loss: 0.8239 - val_accuracy: 0.6771\n",
            "Epoch 171/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1048 - accuracy: 0.9598 - val_loss: 0.8443 - val_accuracy: 0.7292\n",
            "Epoch 172/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1853 - accuracy: 0.9171 - val_loss: 0.9437 - val_accuracy: 0.6979\n",
            "Epoch 173/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1604 - accuracy: 0.9560 - val_loss: 0.6304 - val_accuracy: 0.7708\n",
            "Epoch 174/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.2069 - accuracy: 0.9275 - val_loss: 0.8172 - val_accuracy: 0.7083\n",
            "Epoch 175/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1736 - accuracy: 0.9417 - val_loss: 0.8910 - val_accuracy: 0.7396\n",
            "Epoch 176/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1470 - accuracy: 0.9495 - val_loss: 0.8079 - val_accuracy: 0.7396\n",
            "Epoch 177/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1005 - accuracy: 0.9663 - val_loss: 0.9217 - val_accuracy: 0.7188\n",
            "Epoch 178/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1416 - accuracy: 0.9547 - val_loss: 0.8853 - val_accuracy: 0.7083\n",
            "Epoch 179/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1664 - accuracy: 0.9443 - val_loss: 0.8578 - val_accuracy: 0.7188\n",
            "Epoch 180/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1538 - accuracy: 0.9456 - val_loss: 0.9254 - val_accuracy: 0.6979\n",
            "Epoch 181/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2310 - accuracy: 0.9521 - val_loss: 0.9526 - val_accuracy: 0.6979\n",
            "Epoch 182/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1334 - accuracy: 0.9611 - val_loss: 0.9431 - val_accuracy: 0.6979\n",
            "Epoch 183/1000\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.1050 - accuracy: 0.9675 - val_loss: 0.8215 - val_accuracy: 0.7292\n",
            "Epoch 184/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.1697 - accuracy: 0.9521 - val_loss: 0.9943 - val_accuracy: 0.7083\n",
            "Epoch 185/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.1002 - accuracy: 0.9624 - val_loss: 0.8667 - val_accuracy: 0.7083\n",
            "Epoch 186/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.4643 - accuracy: 0.9352 - val_loss: 0.9192 - val_accuracy: 0.7188\n",
            "Epoch 187/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1123 - accuracy: 0.9598 - val_loss: 0.9072 - val_accuracy: 0.7083\n",
            "Epoch 188/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1215 - accuracy: 0.9560 - val_loss: 0.9063 - val_accuracy: 0.7188\n",
            "Epoch 189/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1854 - accuracy: 0.9521 - val_loss: 0.9156 - val_accuracy: 0.7083\n",
            "Epoch 190/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1140 - accuracy: 0.9598 - val_loss: 0.8984 - val_accuracy: 0.7188\n",
            "Epoch 191/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1043 - accuracy: 0.9637 - val_loss: 0.8396 - val_accuracy: 0.7188\n",
            "Epoch 192/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1198 - accuracy: 0.9676 - val_loss: 0.8524 - val_accuracy: 0.7396\n",
            "Epoch 193/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2420 - accuracy: 0.9443 - val_loss: 1.1507 - val_accuracy: 0.7083\n",
            "Epoch 194/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0997 - accuracy: 0.9689 - val_loss: 0.8493 - val_accuracy: 0.7396\n",
            "Epoch 195/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1630 - accuracy: 0.9482 - val_loss: 0.9428 - val_accuracy: 0.7396\n",
            "Epoch 196/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1043 - accuracy: 0.9663 - val_loss: 0.8647 - val_accuracy: 0.7292\n",
            "Epoch 197/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1337 - accuracy: 0.9611 - val_loss: 1.0279 - val_accuracy: 0.7188\n",
            "Epoch 198/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1196 - accuracy: 0.9534 - val_loss: 0.8458 - val_accuracy: 0.7396\n",
            "Epoch 199/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.1552 - accuracy: 0.9676 - val_loss: 0.8434 - val_accuracy: 0.7188\n",
            "Epoch 200/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1159 - accuracy: 0.9611 - val_loss: 0.9390 - val_accuracy: 0.7188\n",
            "Epoch 201/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1080 - accuracy: 0.9663 - val_loss: 0.9458 - val_accuracy: 0.7292\n",
            "Epoch 202/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1017 - accuracy: 0.9637 - val_loss: 0.8904 - val_accuracy: 0.7188\n",
            "Epoch 203/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1118 - accuracy: 0.9637 - val_loss: 0.9790 - val_accuracy: 0.7083\n",
            "Epoch 204/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1094 - accuracy: 0.9611 - val_loss: 0.9372 - val_accuracy: 0.7083\n",
            "Epoch 205/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0997 - accuracy: 0.9598 - val_loss: 0.8322 - val_accuracy: 0.7396\n",
            "Epoch 206/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1201 - accuracy: 0.9715 - val_loss: 0.8115 - val_accuracy: 0.7396\n",
            "Epoch 207/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1155 - accuracy: 0.9676 - val_loss: 0.8170 - val_accuracy: 0.7396\n",
            "Epoch 208/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1153 - accuracy: 0.9676 - val_loss: 0.8725 - val_accuracy: 0.7396\n",
            "Epoch 209/1000\n",
            "25/25 [==============================] - 5s 212ms/step - loss: 0.1004 - accuracy: 0.9613 - val_loss: 0.8758 - val_accuracy: 0.7188\n",
            "Epoch 210/1000\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.1219 - accuracy: 0.9573 - val_loss: 0.8933 - val_accuracy: 0.7083\n",
            "Epoch 211/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.1717 - accuracy: 0.9534 - val_loss: 0.8797 - val_accuracy: 0.7188\n",
            "Epoch 212/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1545 - accuracy: 0.9521 - val_loss: 0.9192 - val_accuracy: 0.7188\n",
            "Epoch 213/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.2029 - accuracy: 0.9482 - val_loss: 0.8242 - val_accuracy: 0.7292\n",
            "Epoch 214/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1706 - accuracy: 0.9560 - val_loss: 0.9842 - val_accuracy: 0.7188\n",
            "Epoch 215/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1429 - accuracy: 0.9650 - val_loss: 0.9687 - val_accuracy: 0.7188\n",
            "Epoch 216/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1287 - accuracy: 0.9637 - val_loss: 0.9112 - val_accuracy: 0.7188\n",
            "Epoch 217/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1034 - accuracy: 0.9741 - val_loss: 0.8219 - val_accuracy: 0.7292\n",
            "Epoch 218/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.2713 - accuracy: 0.9508 - val_loss: 1.1485 - val_accuracy: 0.6042\n",
            "Epoch 219/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1305 - accuracy: 0.9598 - val_loss: 0.9107 - val_accuracy: 0.7292\n",
            "Epoch 220/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0981 - accuracy: 0.9624 - val_loss: 0.8087 - val_accuracy: 0.7396\n",
            "Epoch 221/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1493 - accuracy: 0.9585 - val_loss: 1.0171 - val_accuracy: 0.7292\n",
            "Epoch 222/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0773 - accuracy: 0.9780 - val_loss: 0.8630 - val_accuracy: 0.7292\n",
            "Epoch 223/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1186 - accuracy: 0.9767 - val_loss: 0.9330 - val_accuracy: 0.7500\n",
            "Epoch 224/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1796 - accuracy: 0.9728 - val_loss: 1.1961 - val_accuracy: 0.6979\n",
            "Epoch 225/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1843 - accuracy: 0.9521 - val_loss: 0.9783 - val_accuracy: 0.6562\n",
            "Epoch 226/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1732 - accuracy: 0.9547 - val_loss: 1.1735 - val_accuracy: 0.6979\n",
            "Epoch 227/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1423 - accuracy: 0.9508 - val_loss: 1.0532 - val_accuracy: 0.7188\n",
            "Epoch 228/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1659 - accuracy: 0.9650 - val_loss: 0.7099 - val_accuracy: 0.7708\n",
            "Epoch 229/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1814 - accuracy: 0.9495 - val_loss: 0.8271 - val_accuracy: 0.7396\n",
            "Epoch 230/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1441 - accuracy: 0.9676 - val_loss: 1.1926 - val_accuracy: 0.6250\n",
            "Epoch 231/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0914 - accuracy: 0.9715 - val_loss: 0.9293 - val_accuracy: 0.7292\n",
            "Epoch 232/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0919 - accuracy: 0.9728 - val_loss: 0.8337 - val_accuracy: 0.7396\n",
            "Epoch 233/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0953 - accuracy: 0.9702 - val_loss: 0.8481 - val_accuracy: 0.7500\n",
            "Epoch 234/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0736 - accuracy: 0.9780 - val_loss: 0.8669 - val_accuracy: 0.7292\n",
            "Epoch 235/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0799 - accuracy: 0.9750 - val_loss: 0.9479 - val_accuracy: 0.7188\n",
            "Epoch 236/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1116 - accuracy: 0.9663 - val_loss: 0.9792 - val_accuracy: 0.7083\n",
            "Epoch 237/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1758 - accuracy: 0.9495 - val_loss: 0.9466 - val_accuracy: 0.7292\n",
            "Epoch 238/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1105 - accuracy: 0.9611 - val_loss: 0.8196 - val_accuracy: 0.7292\n",
            "Epoch 239/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1525 - accuracy: 0.9404 - val_loss: 0.8468 - val_accuracy: 0.7396\n",
            "Epoch 240/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1269 - accuracy: 0.9650 - val_loss: 0.8359 - val_accuracy: 0.7396\n",
            "Epoch 241/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1128 - accuracy: 0.9754 - val_loss: 0.9109 - val_accuracy: 0.7292\n",
            "Epoch 242/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0959 - accuracy: 0.9715 - val_loss: 0.9375 - val_accuracy: 0.7188\n",
            "Epoch 243/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0948 - accuracy: 0.9741 - val_loss: 0.8471 - val_accuracy: 0.7396\n",
            "Epoch 244/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1081 - accuracy: 0.9676 - val_loss: 0.8857 - val_accuracy: 0.7396\n",
            "Epoch 245/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0814 - accuracy: 0.9741 - val_loss: 0.8591 - val_accuracy: 0.7396\n",
            "Epoch 246/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1322 - accuracy: 0.9650 - val_loss: 1.0489 - val_accuracy: 0.6979\n",
            "Epoch 247/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.1736 - accuracy: 0.9728 - val_loss: 0.6455 - val_accuracy: 0.8229\n",
            "Epoch 248/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1347 - accuracy: 0.9585 - val_loss: 0.8811 - val_accuracy: 0.7500\n",
            "Epoch 249/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.2000 - accuracy: 0.9443 - val_loss: 0.7673 - val_accuracy: 0.7500\n",
            "Epoch 250/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1196 - accuracy: 0.9598 - val_loss: 0.9801 - val_accuracy: 0.7292\n",
            "Epoch 251/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1445 - accuracy: 0.9715 - val_loss: 0.7476 - val_accuracy: 0.7812\n",
            "Epoch 252/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1160 - accuracy: 0.9547 - val_loss: 0.8857 - val_accuracy: 0.7500\n",
            "Epoch 253/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0800 - accuracy: 0.9689 - val_loss: 0.9428 - val_accuracy: 0.7188\n",
            "Epoch 254/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0966 - accuracy: 0.9832 - val_loss: 0.9706 - val_accuracy: 0.7188\n",
            "Epoch 255/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1275 - accuracy: 0.9547 - val_loss: 0.9198 - val_accuracy: 0.7396\n",
            "Epoch 256/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0992 - accuracy: 0.9663 - val_loss: 0.8846 - val_accuracy: 0.7292\n",
            "Epoch 257/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1712 - accuracy: 0.9663 - val_loss: 0.8835 - val_accuracy: 0.7500\n",
            "Epoch 258/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1120 - accuracy: 0.9547 - val_loss: 0.8578 - val_accuracy: 0.7604\n",
            "Epoch 259/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1335 - accuracy: 0.9728 - val_loss: 0.7863 - val_accuracy: 0.7500\n",
            "Epoch 260/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0953 - accuracy: 0.9676 - val_loss: 0.9412 - val_accuracy: 0.7292\n",
            "Epoch 261/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 0.8689 - val_accuracy: 0.7396\n",
            "Epoch 262/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1564 - accuracy: 0.9573 - val_loss: 0.9894 - val_accuracy: 0.7292\n",
            "Epoch 263/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0879 - accuracy: 0.9715 - val_loss: 0.8832 - val_accuracy: 0.7500\n",
            "Epoch 264/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1093 - accuracy: 0.9689 - val_loss: 0.8872 - val_accuracy: 0.7500\n",
            "Epoch 265/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1296 - accuracy: 0.9650 - val_loss: 0.8642 - val_accuracy: 0.7500\n",
            "Epoch 266/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0992 - accuracy: 0.9728 - val_loss: 0.8552 - val_accuracy: 0.7604\n",
            "Epoch 267/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0806 - accuracy: 0.9741 - val_loss: 0.8855 - val_accuracy: 0.7396\n",
            "Epoch 268/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0812 - accuracy: 0.9754 - val_loss: 0.8510 - val_accuracy: 0.7500\n",
            "Epoch 269/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1199 - accuracy: 0.9663 - val_loss: 0.8081 - val_accuracy: 0.7708\n",
            "Epoch 270/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0655 - accuracy: 0.9793 - val_loss: 0.8530 - val_accuracy: 0.7500\n",
            "Epoch 271/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1265 - accuracy: 0.9624 - val_loss: 0.9037 - val_accuracy: 0.7396\n",
            "Epoch 272/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1658 - accuracy: 0.9598 - val_loss: 0.9034 - val_accuracy: 0.7396\n",
            "Epoch 273/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0786 - accuracy: 0.9754 - val_loss: 0.8593 - val_accuracy: 0.7500\n",
            "Epoch 274/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1275 - accuracy: 0.9585 - val_loss: 0.9072 - val_accuracy: 0.7292\n",
            "Epoch 275/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1855 - accuracy: 0.9689 - val_loss: 0.7215 - val_accuracy: 0.7604\n",
            "Epoch 276/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0754 - accuracy: 0.9754 - val_loss: 0.8036 - val_accuracy: 0.7604\n",
            "Epoch 277/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0582 - accuracy: 0.9832 - val_loss: 1.0751 - val_accuracy: 0.6875\n",
            "Epoch 278/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1069 - accuracy: 0.9715 - val_loss: 0.9777 - val_accuracy: 0.7604\n",
            "Epoch 279/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1105 - accuracy: 0.9819 - val_loss: 1.0030 - val_accuracy: 0.7396\n",
            "Epoch 280/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1005 - accuracy: 0.9767 - val_loss: 0.9360 - val_accuracy: 0.7188\n",
            "Epoch 281/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1038 - accuracy: 0.9715 - val_loss: 1.1033 - val_accuracy: 0.7396\n",
            "Epoch 282/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1572 - accuracy: 0.9585 - val_loss: 1.0927 - val_accuracy: 0.6250\n",
            "Epoch 283/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1320 - accuracy: 0.9585 - val_loss: 0.9365 - val_accuracy: 0.7396\n",
            "Epoch 284/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0630 - accuracy: 0.9806 - val_loss: 0.8027 - val_accuracy: 0.7500\n",
            "Epoch 285/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1127 - accuracy: 0.9637 - val_loss: 0.8779 - val_accuracy: 0.7396\n",
            "Epoch 286/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1041 - accuracy: 0.9676 - val_loss: 0.8237 - val_accuracy: 0.7500\n",
            "Epoch 287/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0674 - accuracy: 0.9787 - val_loss: 0.8625 - val_accuracy: 0.7604\n",
            "Epoch 288/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.1188 - accuracy: 0.9819 - val_loss: 0.7749 - val_accuracy: 0.7708\n",
            "Epoch 289/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1049 - accuracy: 0.9754 - val_loss: 1.0029 - val_accuracy: 0.7396\n",
            "Epoch 290/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0694 - accuracy: 0.9780 - val_loss: 0.8235 - val_accuracy: 0.7604\n",
            "Epoch 291/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1370 - accuracy: 0.9689 - val_loss: 1.1242 - val_accuracy: 0.6875\n",
            "Epoch 292/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.2244 - accuracy: 0.9637 - val_loss: 0.9327 - val_accuracy: 0.7604\n",
            "Epoch 293/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0615 - accuracy: 0.9793 - val_loss: 0.8542 - val_accuracy: 0.7500\n",
            "Epoch 294/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0695 - accuracy: 0.9767 - val_loss: 0.9504 - val_accuracy: 0.7396\n",
            "Epoch 295/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0686 - accuracy: 0.9819 - val_loss: 0.8641 - val_accuracy: 0.7604\n",
            "Epoch 296/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1153 - accuracy: 0.9676 - val_loss: 0.8664 - val_accuracy: 0.7292\n",
            "Epoch 297/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0977 - accuracy: 0.9728 - val_loss: 0.8574 - val_accuracy: 0.7396\n",
            "Epoch 298/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0695 - accuracy: 0.9780 - val_loss: 1.0015 - val_accuracy: 0.7396\n",
            "Epoch 299/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0799 - accuracy: 0.9728 - val_loss: 0.7379 - val_accuracy: 0.7708\n",
            "Epoch 300/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.2293 - accuracy: 0.9482 - val_loss: 0.9384 - val_accuracy: 0.6979\n",
            "Epoch 301/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0685 - accuracy: 0.9767 - val_loss: 1.0060 - val_accuracy: 0.7188\n",
            "Epoch 302/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0712 - accuracy: 0.9832 - val_loss: 0.9931 - val_accuracy: 0.7292\n",
            "Epoch 303/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0694 - accuracy: 0.9780 - val_loss: 1.0372 - val_accuracy: 0.7292\n",
            "Epoch 304/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0809 - accuracy: 0.9767 - val_loss: 0.6933 - val_accuracy: 0.8021\n",
            "Epoch 305/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1533 - accuracy: 0.9650 - val_loss: 0.9391 - val_accuracy: 0.7500\n",
            "Epoch 306/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1774 - accuracy: 0.9702 - val_loss: 0.8987 - val_accuracy: 0.7604\n",
            "Epoch 307/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1279 - accuracy: 0.9650 - val_loss: 0.8729 - val_accuracy: 0.7604\n",
            "Epoch 308/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1135 - accuracy: 0.9741 - val_loss: 1.0162 - val_accuracy: 0.6667\n",
            "Epoch 309/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0948 - accuracy: 0.9715 - val_loss: 1.0501 - val_accuracy: 0.7292\n",
            "Epoch 310/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0854 - accuracy: 0.9715 - val_loss: 0.9165 - val_accuracy: 0.7500\n",
            "Epoch 311/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0708 - accuracy: 0.9832 - val_loss: 0.9229 - val_accuracy: 0.7500\n",
            "Epoch 312/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1504 - accuracy: 0.9715 - val_loss: 0.8616 - val_accuracy: 0.7500\n",
            "Epoch 313/1000\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.1007 - accuracy: 0.9663 - val_loss: 0.7171 - val_accuracy: 0.7812\n",
            "Epoch 314/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.1192 - accuracy: 0.9702 - val_loss: 0.9538 - val_accuracy: 0.7292\n",
            "Epoch 315/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0616 - accuracy: 0.9832 - val_loss: 0.9460 - val_accuracy: 0.7500\n",
            "Epoch 316/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.2199 - accuracy: 0.9585 - val_loss: 0.8608 - val_accuracy: 0.7396\n",
            "Epoch 317/1000\n",
            "25/25 [==============================] - 5s 208ms/step - loss: 0.0758 - accuracy: 0.9858 - val_loss: 0.8895 - val_accuracy: 0.7604\n",
            "Epoch 318/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1139 - accuracy: 0.9624 - val_loss: 1.0013 - val_accuracy: 0.7396\n",
            "Epoch 319/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1479 - accuracy: 0.9676 - val_loss: 1.1177 - val_accuracy: 0.6562\n",
            "Epoch 320/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0685 - accuracy: 0.9845 - val_loss: 0.9047 - val_accuracy: 0.7604\n",
            "Epoch 321/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0609 - accuracy: 0.9767 - val_loss: 0.8659 - val_accuracy: 0.7604\n",
            "Epoch 322/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0714 - accuracy: 0.9780 - val_loss: 0.9431 - val_accuracy: 0.7500\n",
            "Epoch 323/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0602 - accuracy: 0.9909 - val_loss: 0.8074 - val_accuracy: 0.7812\n",
            "Epoch 324/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1261 - accuracy: 0.9767 - val_loss: 0.8484 - val_accuracy: 0.7708\n",
            "Epoch 325/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1519 - accuracy: 0.9663 - val_loss: 0.6252 - val_accuracy: 0.7917\n",
            "Epoch 326/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0894 - accuracy: 0.9728 - val_loss: 1.1305 - val_accuracy: 0.6979\n",
            "Epoch 327/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0568 - accuracy: 0.9858 - val_loss: 1.0350 - val_accuracy: 0.6771\n",
            "Epoch 328/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.1295 - accuracy: 0.9780 - val_loss: 0.9696 - val_accuracy: 0.7500\n",
            "Epoch 329/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0954 - accuracy: 0.9637 - val_loss: 1.0154 - val_accuracy: 0.6875\n",
            "Epoch 330/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0638 - accuracy: 0.9896 - val_loss: 0.8412 - val_accuracy: 0.7396\n",
            "Epoch 331/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1071 - accuracy: 0.9728 - val_loss: 0.8819 - val_accuracy: 0.7604\n",
            "Epoch 332/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0942 - accuracy: 0.9741 - val_loss: 0.9451 - val_accuracy: 0.7500\n",
            "Epoch 333/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1025 - accuracy: 0.9806 - val_loss: 1.0008 - val_accuracy: 0.7396\n",
            "Epoch 334/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0579 - accuracy: 0.9870 - val_loss: 0.7611 - val_accuracy: 0.7812\n",
            "Epoch 335/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0836 - accuracy: 0.9702 - val_loss: 0.8781 - val_accuracy: 0.7604\n",
            "Epoch 336/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1237 - accuracy: 0.9767 - val_loss: 1.0719 - val_accuracy: 0.7396\n",
            "Epoch 337/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0765 - accuracy: 0.9754 - val_loss: 1.0081 - val_accuracy: 0.7188\n",
            "Epoch 338/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1637 - accuracy: 0.9793 - val_loss: 0.8027 - val_accuracy: 0.7708\n",
            "Epoch 339/1000\n",
            "25/25 [==============================] - 5s 208ms/step - loss: 0.1057 - accuracy: 0.9563 - val_loss: 0.9265 - val_accuracy: 0.7500\n",
            "Epoch 340/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0605 - accuracy: 0.9754 - val_loss: 0.8634 - val_accuracy: 0.7604\n",
            "Epoch 341/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0818 - accuracy: 0.9767 - val_loss: 0.9319 - val_accuracy: 0.7500\n",
            "Epoch 342/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0649 - accuracy: 0.9845 - val_loss: 0.9314 - val_accuracy: 0.7604\n",
            "Epoch 343/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.9780 - val_accuracy: 0.7396\n",
            "Epoch 344/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0641 - accuracy: 0.9806 - val_loss: 0.8545 - val_accuracy: 0.7604\n",
            "Epoch 345/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1223 - accuracy: 0.9715 - val_loss: 0.8840 - val_accuracy: 0.7708\n",
            "Epoch 346/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 0.9506 - val_accuracy: 0.7604\n",
            "Epoch 347/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0525 - accuracy: 0.9883 - val_loss: 0.8483 - val_accuracy: 0.7604\n",
            "Epoch 348/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1280 - accuracy: 0.9702 - val_loss: 0.8250 - val_accuracy: 0.7708\n",
            "Epoch 349/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0563 - accuracy: 0.9845 - val_loss: 0.9147 - val_accuracy: 0.7604\n",
            "Epoch 350/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.3697 - accuracy: 0.9391 - val_loss: 0.7134 - val_accuracy: 0.8021\n",
            "Epoch 351/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0883 - accuracy: 0.9715 - val_loss: 0.9493 - val_accuracy: 0.7604\n",
            "Epoch 352/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1213 - accuracy: 0.9806 - val_loss: 1.1019 - val_accuracy: 0.7083\n",
            "Epoch 353/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0584 - accuracy: 0.9819 - val_loss: 0.9656 - val_accuracy: 0.7396\n",
            "Epoch 354/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0655 - accuracy: 0.9780 - val_loss: 1.1501 - val_accuracy: 0.6667\n",
            "Epoch 355/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0535 - accuracy: 0.9819 - val_loss: 0.9739 - val_accuracy: 0.7396\n",
            "Epoch 356/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1452 - accuracy: 0.9870 - val_loss: 0.9180 - val_accuracy: 0.6875\n",
            "Epoch 357/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0957 - accuracy: 0.9663 - val_loss: 1.0204 - val_accuracy: 0.7292\n",
            "Epoch 358/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0728 - accuracy: 0.9793 - val_loss: 0.8439 - val_accuracy: 0.7604\n",
            "Epoch 359/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0611 - accuracy: 0.9793 - val_loss: 0.9512 - val_accuracy: 0.7396\n",
            "Epoch 360/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0615 - accuracy: 0.9845 - val_loss: 1.0131 - val_accuracy: 0.7500\n",
            "Epoch 361/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0623 - accuracy: 0.9767 - val_loss: 0.9613 - val_accuracy: 0.7083\n",
            "Epoch 362/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1632 - accuracy: 0.9741 - val_loss: 0.9183 - val_accuracy: 0.7708\n",
            "Epoch 363/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0866 - accuracy: 0.9689 - val_loss: 0.9539 - val_accuracy: 0.7500\n",
            "Epoch 364/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0717 - accuracy: 0.9832 - val_loss: 0.8922 - val_accuracy: 0.7708\n",
            "Epoch 365/1000\n",
            "25/25 [==============================] - 5s 210ms/step - loss: 0.0593 - accuracy: 0.9837 - val_loss: 0.9211 - val_accuracy: 0.7500\n",
            "Epoch 366/1000\n",
            "25/25 [==============================] - 5s 208ms/step - loss: 0.1433 - accuracy: 0.9676 - val_loss: 0.9643 - val_accuracy: 0.7500\n",
            "Epoch 367/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0756 - accuracy: 0.9845 - val_loss: 0.9346 - val_accuracy: 0.7604\n",
            "Epoch 368/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1807 - accuracy: 0.9728 - val_loss: 0.8554 - val_accuracy: 0.7604\n",
            "Epoch 369/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0434 - accuracy: 0.9883 - val_loss: 0.8495 - val_accuracy: 0.7708\n",
            "Epoch 370/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0471 - accuracy: 0.9909 - val_loss: 0.8986 - val_accuracy: 0.7604\n",
            "Epoch 371/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1780 - accuracy: 0.9767 - val_loss: 0.8003 - val_accuracy: 0.7708\n",
            "Epoch 372/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0535 - accuracy: 0.9845 - val_loss: 1.1182 - val_accuracy: 0.6667\n",
            "Epoch 373/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0973 - accuracy: 0.9741 - val_loss: 1.0675 - val_accuracy: 0.7188\n",
            "Epoch 374/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0879 - accuracy: 0.9741 - val_loss: 1.1847 - val_accuracy: 0.6250\n",
            "Epoch 375/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0431 - accuracy: 0.9909 - val_loss: 0.8577 - val_accuracy: 0.7708\n",
            "Epoch 376/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1481 - accuracy: 0.9741 - val_loss: 1.0023 - val_accuracy: 0.7083\n",
            "Epoch 377/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1607 - accuracy: 0.9702 - val_loss: 1.0209 - val_accuracy: 0.7500\n",
            "Epoch 378/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0675 - accuracy: 0.9754 - val_loss: 0.9139 - val_accuracy: 0.7500\n",
            "Epoch 379/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0592 - accuracy: 0.9896 - val_loss: 1.1125 - val_accuracy: 0.7396\n",
            "Epoch 380/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0637 - accuracy: 0.9793 - val_loss: 0.8728 - val_accuracy: 0.7812\n",
            "Epoch 381/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.2991 - accuracy: 0.9741 - val_loss: 1.0590 - val_accuracy: 0.7292\n",
            "Epoch 382/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0917 - accuracy: 0.9624 - val_loss: 0.8591 - val_accuracy: 0.7708\n",
            "Epoch 383/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 1.0103 - val_accuracy: 0.7396\n",
            "Epoch 384/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1306 - accuracy: 0.9754 - val_loss: 1.3685 - val_accuracy: 0.6146\n",
            "Epoch 385/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0626 - accuracy: 0.9806 - val_loss: 0.9591 - val_accuracy: 0.7396\n",
            "Epoch 386/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.1027 - accuracy: 0.9793 - val_loss: 0.8629 - val_accuracy: 0.7604\n",
            "Epoch 387/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0955 - accuracy: 0.9780 - val_loss: 0.8009 - val_accuracy: 0.7812\n",
            "Epoch 388/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0639 - accuracy: 0.9793 - val_loss: 0.8997 - val_accuracy: 0.7604\n",
            "Epoch 389/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0637 - accuracy: 0.9806 - val_loss: 0.9741 - val_accuracy: 0.7604\n",
            "Epoch 390/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0440 - accuracy: 0.9832 - val_loss: 1.0153 - val_accuracy: 0.7396\n",
            "Epoch 391/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.0442 - accuracy: 0.9887 - val_loss: 0.9527 - val_accuracy: 0.7500\n",
            "Epoch 392/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0605 - accuracy: 0.9832 - val_loss: 0.9150 - val_accuracy: 0.7604\n",
            "Epoch 393/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0971 - accuracy: 0.9754 - val_loss: 0.9711 - val_accuracy: 0.7604\n",
            "Epoch 394/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1206 - accuracy: 0.9663 - val_loss: 0.9743 - val_accuracy: 0.7396\n",
            "Epoch 395/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1920 - accuracy: 0.9676 - val_loss: 0.9336 - val_accuracy: 0.7604\n",
            "Epoch 396/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.9229 - val_accuracy: 0.7500\n",
            "Epoch 397/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0489 - accuracy: 0.9819 - val_loss: 1.0519 - val_accuracy: 0.7292\n",
            "Epoch 398/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1392 - accuracy: 0.9702 - val_loss: 0.9104 - val_accuracy: 0.7500\n",
            "Epoch 399/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0449 - accuracy: 0.9896 - val_loss: 0.9637 - val_accuracy: 0.7604\n",
            "Epoch 400/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.8186 - val_accuracy: 0.7708\n",
            "Epoch 401/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1634 - accuracy: 0.9689 - val_loss: 0.6291 - val_accuracy: 0.8229\n",
            "Epoch 402/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0697 - accuracy: 0.9754 - val_loss: 1.0262 - val_accuracy: 0.7396\n",
            "Epoch 403/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0506 - accuracy: 0.9858 - val_loss: 0.9863 - val_accuracy: 0.7396\n",
            "Epoch 404/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.8710 - val_accuracy: 0.7604\n",
            "Epoch 405/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0743 - accuracy: 0.9806 - val_loss: 0.9021 - val_accuracy: 0.7604\n",
            "Epoch 406/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0491 - accuracy: 0.9793 - val_loss: 0.8485 - val_accuracy: 0.7812\n",
            "Epoch 407/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0317 - accuracy: 0.9935 - val_loss: 0.8790 - val_accuracy: 0.7500\n",
            "Epoch 408/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0635 - accuracy: 0.9858 - val_loss: 1.1006 - val_accuracy: 0.7188\n",
            "Epoch 409/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0590 - accuracy: 0.9793 - val_loss: 0.8839 - val_accuracy: 0.7708\n",
            "Epoch 410/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0352 - accuracy: 0.9922 - val_loss: 0.9394 - val_accuracy: 0.7604\n",
            "Epoch 411/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0965 - accuracy: 0.9819 - val_loss: 0.8969 - val_accuracy: 0.7604\n",
            "Epoch 412/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1119 - accuracy: 0.9767 - val_loss: 0.8793 - val_accuracy: 0.7604\n",
            "Epoch 413/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0620 - accuracy: 0.9819 - val_loss: 0.8274 - val_accuracy: 0.7812\n",
            "Epoch 414/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0431 - accuracy: 0.9909 - val_loss: 0.8754 - val_accuracy: 0.7708\n",
            "Epoch 415/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0398 - accuracy: 0.9883 - val_loss: 0.8996 - val_accuracy: 0.7604\n",
            "Epoch 416/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0640 - accuracy: 0.9883 - val_loss: 0.8378 - val_accuracy: 0.7708\n",
            "Epoch 417/1000\n",
            "25/25 [==============================] - 5s 208ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.8611 - val_accuracy: 0.7708\n",
            "Epoch 418/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.1003 - accuracy: 0.9832 - val_loss: 0.9965 - val_accuracy: 0.7292\n",
            "Epoch 419/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1209 - accuracy: 0.9624 - val_loss: 0.8988 - val_accuracy: 0.7708\n",
            "Epoch 420/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0332 - accuracy: 0.9896 - val_loss: 0.8549 - val_accuracy: 0.7812\n",
            "Epoch 421/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0968 - accuracy: 0.9806 - val_loss: 0.8846 - val_accuracy: 0.7708\n",
            "Epoch 422/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0413 - accuracy: 0.9909 - val_loss: 0.9229 - val_accuracy: 0.7708\n",
            "Epoch 423/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0511 - accuracy: 0.9870 - val_loss: 0.8084 - val_accuracy: 0.7708\n",
            "Epoch 424/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.8551 - val_accuracy: 0.7708\n",
            "Epoch 425/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0434 - accuracy: 0.9883 - val_loss: 1.0201 - val_accuracy: 0.7292\n",
            "Epoch 426/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0440 - accuracy: 0.9832 - val_loss: 0.9487 - val_accuracy: 0.7292\n",
            "Epoch 427/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0377 - accuracy: 0.9935 - val_loss: 0.9425 - val_accuracy: 0.7604\n",
            "Epoch 428/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0619 - accuracy: 0.9883 - val_loss: 0.8180 - val_accuracy: 0.7812\n",
            "Epoch 429/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1189 - accuracy: 0.9780 - val_loss: 1.3065 - val_accuracy: 0.6875\n",
            "Epoch 430/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0510 - accuracy: 0.9858 - val_loss: 0.9626 - val_accuracy: 0.7500\n",
            "Epoch 431/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0424 - accuracy: 0.9883 - val_loss: 0.9259 - val_accuracy: 0.7708\n",
            "Epoch 432/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0712 - accuracy: 0.9922 - val_loss: 1.0501 - val_accuracy: 0.7500\n",
            "Epoch 433/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1372 - accuracy: 0.9780 - val_loss: 0.8341 - val_accuracy: 0.7812\n",
            "Epoch 434/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0835 - accuracy: 0.9741 - val_loss: 1.3279 - val_accuracy: 0.6458\n",
            "Epoch 435/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0547 - accuracy: 0.9819 - val_loss: 0.9747 - val_accuracy: 0.7396\n",
            "Epoch 436/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0438 - accuracy: 0.9896 - val_loss: 0.8330 - val_accuracy: 0.7917\n",
            "Epoch 437/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0899 - accuracy: 0.9870 - val_loss: 1.1765 - val_accuracy: 0.6458\n",
            "Epoch 438/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0974 - accuracy: 0.9754 - val_loss: 1.0128 - val_accuracy: 0.7292\n",
            "Epoch 439/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0350 - accuracy: 0.9948 - val_loss: 0.8981 - val_accuracy: 0.7500\n",
            "Epoch 440/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0580 - accuracy: 0.9793 - val_loss: 0.9565 - val_accuracy: 0.7604\n",
            "Epoch 441/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0521 - accuracy: 0.9819 - val_loss: 0.9124 - val_accuracy: 0.7604\n",
            "Epoch 442/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0959 - accuracy: 0.9819 - val_loss: 0.8117 - val_accuracy: 0.7708\n",
            "Epoch 443/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0622 - accuracy: 0.9750 - val_loss: 0.8092 - val_accuracy: 0.7917\n",
            "Epoch 444/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0997 - accuracy: 0.9767 - val_loss: 0.9931 - val_accuracy: 0.7292\n",
            "Epoch 445/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0395 - accuracy: 0.9935 - val_loss: 0.9279 - val_accuracy: 0.7500\n",
            "Epoch 446/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1986 - accuracy: 0.9676 - val_loss: 0.7951 - val_accuracy: 0.7812\n",
            "Epoch 447/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0504 - accuracy: 0.9870 - val_loss: 1.0988 - val_accuracy: 0.7292\n",
            "Epoch 448/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0978 - accuracy: 0.9793 - val_loss: 0.7969 - val_accuracy: 0.7604\n",
            "Epoch 449/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0422 - accuracy: 0.9883 - val_loss: 0.9331 - val_accuracy: 0.7500\n",
            "Epoch 450/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0464 - accuracy: 0.9832 - val_loss: 0.8730 - val_accuracy: 0.7500\n",
            "Epoch 451/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 0.9960 - val_accuracy: 0.7500\n",
            "Epoch 452/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0414 - accuracy: 0.9896 - val_loss: 0.9041 - val_accuracy: 0.7708\n",
            "Epoch 453/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0402 - accuracy: 0.9858 - val_loss: 0.8153 - val_accuracy: 0.7812\n",
            "Epoch 454/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.7936 - val_accuracy: 0.7812\n",
            "Epoch 455/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0365 - accuracy: 0.9858 - val_loss: 0.9324 - val_accuracy: 0.7396\n",
            "Epoch 456/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0752 - accuracy: 0.9832 - val_loss: 0.7994 - val_accuracy: 0.7604\n",
            "Epoch 457/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0619 - accuracy: 0.9806 - val_loss: 0.8859 - val_accuracy: 0.7500\n",
            "Epoch 458/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0861 - accuracy: 0.9883 - val_loss: 0.7254 - val_accuracy: 0.7917\n",
            "Epoch 459/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0780 - accuracy: 0.9819 - val_loss: 1.1510 - val_accuracy: 0.7292\n",
            "Epoch 460/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0548 - accuracy: 0.9870 - val_loss: 0.8532 - val_accuracy: 0.7604\n",
            "Epoch 461/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0400 - accuracy: 0.9909 - val_loss: 0.8499 - val_accuracy: 0.7500\n",
            "Epoch 462/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0847 - accuracy: 0.9896 - val_loss: 0.8517 - val_accuracy: 0.7812\n",
            "Epoch 463/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0698 - accuracy: 0.9780 - val_loss: 0.9253 - val_accuracy: 0.7708\n",
            "Epoch 464/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1320 - accuracy: 0.9819 - val_loss: 0.7612 - val_accuracy: 0.7812\n",
            "Epoch 465/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0821 - accuracy: 0.9741 - val_loss: 0.8714 - val_accuracy: 0.7812\n",
            "Epoch 466/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1347 - accuracy: 0.9883 - val_loss: 0.8593 - val_accuracy: 0.7604\n",
            "Epoch 467/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.9186 - val_accuracy: 0.7604\n",
            "Epoch 468/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0453 - accuracy: 0.9909 - val_loss: 0.9165 - val_accuracy: 0.7708\n",
            "Epoch 469/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.0373 - accuracy: 0.9912 - val_loss: 0.9473 - val_accuracy: 0.7500\n",
            "Epoch 470/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0347 - accuracy: 0.9909 - val_loss: 0.8575 - val_accuracy: 0.7917\n",
            "Epoch 471/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0581 - accuracy: 0.9858 - val_loss: 0.9428 - val_accuracy: 0.7604\n",
            "Epoch 472/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.9254 - val_accuracy: 0.7812\n",
            "Epoch 473/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0510 - accuracy: 0.9883 - val_loss: 1.0129 - val_accuracy: 0.7500\n",
            "Epoch 474/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0474 - accuracy: 0.9819 - val_loss: 0.9396 - val_accuracy: 0.7500\n",
            "Epoch 475/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1496 - accuracy: 0.9624 - val_loss: 1.0131 - val_accuracy: 0.7500\n",
            "Epoch 476/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.9132 - val_accuracy: 0.7604\n",
            "Epoch 477/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0838 - accuracy: 0.9858 - val_loss: 0.8706 - val_accuracy: 0.7812\n",
            "Epoch 478/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0846 - accuracy: 0.9845 - val_loss: 0.9551 - val_accuracy: 0.7708\n",
            "Epoch 479/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0427 - accuracy: 0.9858 - val_loss: 0.9388 - val_accuracy: 0.7500\n",
            "Epoch 480/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0517 - accuracy: 0.9883 - val_loss: 1.0946 - val_accuracy: 0.7083\n",
            "Epoch 481/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0409 - accuracy: 0.9883 - val_loss: 1.0697 - val_accuracy: 0.7188\n",
            "Epoch 482/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1053 - accuracy: 0.9896 - val_loss: 0.7100 - val_accuracy: 0.7812\n",
            "Epoch 483/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0594 - accuracy: 0.9832 - val_loss: 0.9145 - val_accuracy: 0.7708\n",
            "Epoch 484/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1338 - accuracy: 0.9896 - val_loss: 0.8400 - val_accuracy: 0.7604\n",
            "Epoch 485/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0363 - accuracy: 0.9909 - val_loss: 0.9314 - val_accuracy: 0.7604\n",
            "Epoch 486/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1572 - accuracy: 0.9883 - val_loss: 1.7005 - val_accuracy: 0.5938\n",
            "Epoch 487/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0689 - accuracy: 0.9728 - val_loss: 0.9720 - val_accuracy: 0.7604\n",
            "Epoch 488/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.0766 - accuracy: 0.9870 - val_loss: 0.8093 - val_accuracy: 0.7812\n",
            "Epoch 489/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0389 - accuracy: 0.9909 - val_loss: 0.9137 - val_accuracy: 0.7604\n",
            "Epoch 490/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0324 - accuracy: 0.9922 - val_loss: 1.0319 - val_accuracy: 0.7500\n",
            "Epoch 491/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0849 - accuracy: 0.9845 - val_loss: 0.9648 - val_accuracy: 0.7396\n",
            "Epoch 492/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1861 - accuracy: 0.9780 - val_loss: 0.7283 - val_accuracy: 0.8021\n",
            "Epoch 493/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.2218 - accuracy: 0.9637 - val_loss: 0.7462 - val_accuracy: 0.7917\n",
            "Epoch 494/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1030 - accuracy: 0.9883 - val_loss: 1.1609 - val_accuracy: 0.7083\n",
            "Epoch 495/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0400 - accuracy: 0.9887 - val_loss: 0.7444 - val_accuracy: 0.7917\n",
            "Epoch 496/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.9382 - val_accuracy: 0.7604\n",
            "Epoch 497/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0741 - accuracy: 0.9870 - val_loss: 1.0967 - val_accuracy: 0.7188\n",
            "Epoch 498/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0654 - accuracy: 0.9845 - val_loss: 1.0005 - val_accuracy: 0.7500\n",
            "Epoch 499/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0519 - accuracy: 0.9896 - val_loss: 1.4663 - val_accuracy: 0.6667\n",
            "Epoch 500/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0780 - accuracy: 0.9676 - val_loss: 1.0049 - val_accuracy: 0.7500\n",
            "Epoch 501/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0607 - accuracy: 0.9883 - val_loss: 0.9867 - val_accuracy: 0.7604\n",
            "Epoch 502/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0852 - accuracy: 0.9896 - val_loss: 1.2311 - val_accuracy: 0.6667\n",
            "Epoch 503/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1288 - accuracy: 0.9767 - val_loss: 1.1308 - val_accuracy: 0.7188\n",
            "Epoch 504/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1382 - accuracy: 0.9754 - val_loss: 0.8344 - val_accuracy: 0.7396\n",
            "Epoch 505/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.2470 - accuracy: 0.9741 - val_loss: 1.6422 - val_accuracy: 0.6042\n",
            "Epoch 506/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0360 - accuracy: 0.9909 - val_loss: 1.1408 - val_accuracy: 0.7083\n",
            "Epoch 507/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1028 - accuracy: 0.9767 - val_loss: 1.4011 - val_accuracy: 0.6875\n",
            "Epoch 508/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0281 - accuracy: 0.9922 - val_loss: 1.0576 - val_accuracy: 0.7396\n",
            "Epoch 509/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.1689 - accuracy: 0.9883 - val_loss: 0.8875 - val_accuracy: 0.7396\n",
            "Epoch 510/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1152 - accuracy: 0.9819 - val_loss: 1.0630 - val_accuracy: 0.7292\n",
            "Epoch 511/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0523 - accuracy: 0.9896 - val_loss: 1.2308 - val_accuracy: 0.7188\n",
            "Epoch 512/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0502 - accuracy: 0.9883 - val_loss: 1.0419 - val_accuracy: 0.7292\n",
            "Epoch 513/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0495 - accuracy: 0.9845 - val_loss: 1.0785 - val_accuracy: 0.7188\n",
            "Epoch 514/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0580 - accuracy: 0.9845 - val_loss: 1.1736 - val_accuracy: 0.7083\n",
            "Epoch 515/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0698 - accuracy: 0.9870 - val_loss: 1.3677 - val_accuracy: 0.6875\n",
            "Epoch 516/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0711 - accuracy: 0.9896 - val_loss: 1.1115 - val_accuracy: 0.7083\n",
            "Epoch 517/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0402 - accuracy: 0.9858 - val_loss: 0.9220 - val_accuracy: 0.7396\n",
            "Epoch 518/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0423 - accuracy: 0.9909 - val_loss: 1.0522 - val_accuracy: 0.7188\n",
            "Epoch 519/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0740 - accuracy: 0.9883 - val_loss: 1.0523 - val_accuracy: 0.7500\n",
            "Epoch 520/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.9493 - val_accuracy: 0.7500\n",
            "Epoch 521/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 1.1204 - val_accuracy: 0.7188\n",
            "Epoch 522/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0405 - accuracy: 0.9922 - val_loss: 1.0370 - val_accuracy: 0.7396\n",
            "Epoch 523/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 1.1126 - val_accuracy: 0.7292\n",
            "Epoch 524/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0767 - accuracy: 0.9845 - val_loss: 0.8690 - val_accuracy: 0.7604\n",
            "Epoch 525/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 1.0149 - val_accuracy: 0.7396\n",
            "Epoch 526/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1017 - accuracy: 0.9845 - val_loss: 1.3489 - val_accuracy: 0.6875\n",
            "Epoch 527/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1562 - accuracy: 0.9741 - val_loss: 1.2335 - val_accuracy: 0.7083\n",
            "Epoch 528/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0544 - accuracy: 0.9845 - val_loss: 0.9565 - val_accuracy: 0.7500\n",
            "Epoch 529/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0271 - accuracy: 0.9935 - val_loss: 0.9397 - val_accuracy: 0.7604\n",
            "Epoch 530/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0292 - accuracy: 0.9961 - val_loss: 1.0097 - val_accuracy: 0.7604\n",
            "Epoch 531/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 1.0205 - val_accuracy: 0.7500\n",
            "Epoch 532/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 1.0684 - val_accuracy: 0.7396\n",
            "Epoch 533/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0336 - accuracy: 0.9909 - val_loss: 0.9234 - val_accuracy: 0.7604\n",
            "Epoch 534/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0363 - accuracy: 0.9845 - val_loss: 0.9372 - val_accuracy: 0.7500\n",
            "Epoch 535/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0661 - accuracy: 0.9922 - val_loss: 0.7944 - val_accuracy: 0.7708\n",
            "Epoch 536/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0859 - accuracy: 0.9715 - val_loss: 1.0815 - val_accuracy: 0.7292\n",
            "Epoch 537/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0412 - accuracy: 0.9896 - val_loss: 0.9626 - val_accuracy: 0.7500\n",
            "Epoch 538/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0546 - accuracy: 0.9806 - val_loss: 1.1433 - val_accuracy: 0.7292\n",
            "Epoch 539/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0377 - accuracy: 0.9922 - val_loss: 1.0756 - val_accuracy: 0.7292\n",
            "Epoch 540/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0356 - accuracy: 0.9922 - val_loss: 0.9400 - val_accuracy: 0.7604\n",
            "Epoch 541/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0861 - accuracy: 0.9883 - val_loss: 1.0578 - val_accuracy: 0.7396\n",
            "Epoch 542/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1772 - accuracy: 0.9819 - val_loss: 1.1491 - val_accuracy: 0.7292\n",
            "Epoch 543/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0620 - accuracy: 0.9780 - val_loss: 1.2320 - val_accuracy: 0.7188\n",
            "Epoch 544/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 0.8680 - val_accuracy: 0.7708\n",
            "Epoch 545/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1282 - accuracy: 0.9870 - val_loss: 1.0908 - val_accuracy: 0.7292\n",
            "Epoch 546/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0900 - accuracy: 0.9793 - val_loss: 1.2438 - val_accuracy: 0.7188\n",
            "Epoch 547/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0479 - accuracy: 0.9862 - val_loss: 1.0372 - val_accuracy: 0.7396\n",
            "Epoch 548/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0306 - accuracy: 0.9883 - val_loss: 1.0312 - val_accuracy: 0.7292\n",
            "Epoch 549/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0999 - accuracy: 0.9832 - val_loss: 0.8967 - val_accuracy: 0.7708\n",
            "Epoch 550/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0375 - accuracy: 0.9896 - val_loss: 1.0603 - val_accuracy: 0.7396\n",
            "Epoch 551/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 1.0390 - val_accuracy: 0.7396\n",
            "Epoch 552/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1081 - accuracy: 0.9806 - val_loss: 1.1040 - val_accuracy: 0.7292\n",
            "Epoch 553/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.3002 - accuracy: 0.9547 - val_loss: 0.9437 - val_accuracy: 0.7604\n",
            "Epoch 554/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0738 - accuracy: 0.9780 - val_loss: 1.1624 - val_accuracy: 0.7188\n",
            "Epoch 555/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0541 - accuracy: 0.9806 - val_loss: 0.9421 - val_accuracy: 0.7708\n",
            "Epoch 556/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2469 - accuracy: 0.9650 - val_loss: 1.2071 - val_accuracy: 0.6667\n",
            "Epoch 557/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0665 - accuracy: 0.9858 - val_loss: 1.2890 - val_accuracy: 0.7083\n",
            "Epoch 558/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1113 - accuracy: 0.9741 - val_loss: 0.7708 - val_accuracy: 0.7812\n",
            "Epoch 559/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0524 - accuracy: 0.9858 - val_loss: 0.9391 - val_accuracy: 0.7604\n",
            "Epoch 560/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0321 - accuracy: 0.9883 - val_loss: 1.0428 - val_accuracy: 0.7396\n",
            "Epoch 561/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.9230 - val_accuracy: 0.7708\n",
            "Epoch 562/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0695 - accuracy: 0.9922 - val_loss: 0.7809 - val_accuracy: 0.7708\n",
            "Epoch 563/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.1383 - accuracy: 0.9793 - val_loss: 1.1056 - val_accuracy: 0.7500\n",
            "Epoch 564/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1045 - accuracy: 0.9858 - val_loss: 1.2030 - val_accuracy: 0.7083\n",
            "Epoch 565/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0750 - accuracy: 0.9832 - val_loss: 0.8900 - val_accuracy: 0.7500\n",
            "Epoch 566/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0570 - accuracy: 0.9845 - val_loss: 0.9980 - val_accuracy: 0.7292\n",
            "Epoch 567/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1119 - accuracy: 0.9896 - val_loss: 0.9943 - val_accuracy: 0.7396\n",
            "Epoch 568/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0682 - accuracy: 0.9832 - val_loss: 1.1022 - val_accuracy: 0.7396\n",
            "Epoch 569/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0778 - accuracy: 0.9819 - val_loss: 1.1166 - val_accuracy: 0.7188\n",
            "Epoch 570/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0567 - accuracy: 0.9883 - val_loss: 1.1048 - val_accuracy: 0.7292\n",
            "Epoch 571/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1696 - accuracy: 0.9845 - val_loss: 1.0920 - val_accuracy: 0.7396\n",
            "Epoch 572/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1194 - accuracy: 0.9689 - val_loss: 1.1607 - val_accuracy: 0.7083\n",
            "Epoch 573/1000\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.0439 - accuracy: 0.9812 - val_loss: 1.0062 - val_accuracy: 0.7292\n",
            "Epoch 574/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0788 - accuracy: 0.9767 - val_loss: 0.9754 - val_accuracy: 0.7396\n",
            "Epoch 575/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0798 - accuracy: 0.9948 - val_loss: 1.2943 - val_accuracy: 0.7083\n",
            "Epoch 576/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1746 - accuracy: 0.9806 - val_loss: 0.9759 - val_accuracy: 0.7396\n",
            "Epoch 577/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0488 - accuracy: 0.9909 - val_loss: 0.8929 - val_accuracy: 0.7917\n",
            "Epoch 578/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0455 - accuracy: 0.9896 - val_loss: 1.0203 - val_accuracy: 0.7396\n",
            "Epoch 579/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0936 - accuracy: 0.9806 - val_loss: 0.9815 - val_accuracy: 0.7604\n",
            "Epoch 580/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0280 - accuracy: 0.9974 - val_loss: 1.0026 - val_accuracy: 0.7396\n",
            "Epoch 581/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1063 - accuracy: 0.9819 - val_loss: 1.0311 - val_accuracy: 0.7500\n",
            "Epoch 582/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0458 - accuracy: 0.9870 - val_loss: 1.0290 - val_accuracy: 0.7292\n",
            "Epoch 583/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0721 - accuracy: 0.9832 - val_loss: 1.1602 - val_accuracy: 0.7188\n",
            "Epoch 584/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1286 - accuracy: 0.9858 - val_loss: 0.7974 - val_accuracy: 0.7917\n",
            "Epoch 585/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1257 - accuracy: 0.9754 - val_loss: 1.3015 - val_accuracy: 0.7188\n",
            "Epoch 586/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0866 - accuracy: 0.9793 - val_loss: 0.9049 - val_accuracy: 0.7604\n",
            "Epoch 587/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1670 - accuracy: 0.9793 - val_loss: 1.3636 - val_accuracy: 0.7083\n",
            "Epoch 588/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0913 - accuracy: 0.9858 - val_loss: 1.0819 - val_accuracy: 0.7292\n",
            "Epoch 589/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 1.0666 - val_accuracy: 0.7396\n",
            "Epoch 590/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 1.0256 - val_accuracy: 0.7396\n",
            "Epoch 591/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0430 - accuracy: 0.9922 - val_loss: 0.9021 - val_accuracy: 0.7604\n",
            "Epoch 592/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 1.0668 - val_accuracy: 0.7292\n",
            "Epoch 593/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 1.0042 - val_accuracy: 0.7500\n",
            "Epoch 594/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 1.0287 - val_accuracy: 0.7292\n",
            "Epoch 595/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0348 - accuracy: 0.9948 - val_loss: 0.9694 - val_accuracy: 0.7604\n",
            "Epoch 596/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0464 - accuracy: 0.9870 - val_loss: 0.8617 - val_accuracy: 0.7500\n",
            "Epoch 597/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0899 - accuracy: 0.9883 - val_loss: 0.9334 - val_accuracy: 0.7500\n",
            "Epoch 598/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0999 - accuracy: 0.9870 - val_loss: 0.8770 - val_accuracy: 0.7604\n",
            "Epoch 599/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.9861 - val_accuracy: 0.7500\n",
            "Epoch 600/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0511 - accuracy: 0.9883 - val_loss: 1.0342 - val_accuracy: 0.7396\n",
            "Epoch 601/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0429 - accuracy: 0.9832 - val_loss: 0.9874 - val_accuracy: 0.7604\n",
            "Epoch 602/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 1.0193 - val_accuracy: 0.7396\n",
            "Epoch 603/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0734 - accuracy: 0.9819 - val_loss: 1.2136 - val_accuracy: 0.7083\n",
            "Epoch 604/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1261 - accuracy: 0.9793 - val_loss: 0.9507 - val_accuracy: 0.7604\n",
            "Epoch 605/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0890 - accuracy: 0.9858 - val_loss: 1.3267 - val_accuracy: 0.6979\n",
            "Epoch 606/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0393 - accuracy: 0.9845 - val_loss: 1.1495 - val_accuracy: 0.7292\n",
            "Epoch 607/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 1.0342 - val_accuracy: 0.7292\n",
            "Epoch 608/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 0.9834 - val_accuracy: 0.7500\n",
            "Epoch 609/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0266 - accuracy: 0.9974 - val_loss: 1.0559 - val_accuracy: 0.7500\n",
            "Epoch 610/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0689 - accuracy: 0.9935 - val_loss: 1.0243 - val_accuracy: 0.7396\n",
            "Epoch 611/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1205 - accuracy: 0.9715 - val_loss: 1.0258 - val_accuracy: 0.7708\n",
            "Epoch 612/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0772 - accuracy: 0.9819 - val_loss: 1.2843 - val_accuracy: 0.6875\n",
            "Epoch 613/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 1.1464 - val_accuracy: 0.7188\n",
            "Epoch 614/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0413 - accuracy: 0.9922 - val_loss: 1.2255 - val_accuracy: 0.6979\n",
            "Epoch 615/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1275 - accuracy: 0.9870 - val_loss: 1.2126 - val_accuracy: 0.7083\n",
            "Epoch 616/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1326 - accuracy: 0.9858 - val_loss: 1.0752 - val_accuracy: 0.7396\n",
            "Epoch 617/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0601 - accuracy: 0.9896 - val_loss: 1.0809 - val_accuracy: 0.7292\n",
            "Epoch 618/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0368 - accuracy: 0.9961 - val_loss: 1.0419 - val_accuracy: 0.7396\n",
            "Epoch 619/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1568 - accuracy: 0.9858 - val_loss: 0.8960 - val_accuracy: 0.7396\n",
            "Epoch 620/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1477 - accuracy: 0.9650 - val_loss: 1.1413 - val_accuracy: 0.7188\n",
            "Epoch 621/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0730 - accuracy: 0.9870 - val_loss: 1.0499 - val_accuracy: 0.7292\n",
            "Epoch 622/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0460 - accuracy: 0.9909 - val_loss: 0.9708 - val_accuracy: 0.7500\n",
            "Epoch 623/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0521 - accuracy: 0.9858 - val_loss: 1.0329 - val_accuracy: 0.7396\n",
            "Epoch 624/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0224 - accuracy: 0.9974 - val_loss: 1.0720 - val_accuracy: 0.7292\n",
            "Epoch 625/1000\n",
            "25/25 [==============================] - 5s 210ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 1.0033 - val_accuracy: 0.7396\n",
            "Epoch 626/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0230 - accuracy: 0.9935 - val_loss: 0.9255 - val_accuracy: 0.7396\n",
            "Epoch 627/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0253 - accuracy: 0.9935 - val_loss: 1.0074 - val_accuracy: 0.7500\n",
            "Epoch 628/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1326 - accuracy: 0.9715 - val_loss: 0.9526 - val_accuracy: 0.7500\n",
            "Epoch 629/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0293 - accuracy: 0.9935 - val_loss: 1.0884 - val_accuracy: 0.7188\n",
            "Epoch 630/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0901 - accuracy: 0.9870 - val_loss: 0.9014 - val_accuracy: 0.7500\n",
            "Epoch 631/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 1.0669 - val_accuracy: 0.7500\n",
            "Epoch 632/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1042 - accuracy: 0.9858 - val_loss: 0.9432 - val_accuracy: 0.7396\n",
            "Epoch 633/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0944 - accuracy: 0.9922 - val_loss: 1.1783 - val_accuracy: 0.7292\n",
            "Epoch 634/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 1.0475 - val_accuracy: 0.7500\n",
            "Epoch 635/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0318 - accuracy: 0.9922 - val_loss: 1.0065 - val_accuracy: 0.7500\n",
            "Epoch 636/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0259 - accuracy: 0.9961 - val_loss: 1.0219 - val_accuracy: 0.7396\n",
            "Epoch 637/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0291 - accuracy: 0.9909 - val_loss: 0.9804 - val_accuracy: 0.7500\n",
            "Epoch 638/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 0.9186 - val_accuracy: 0.7604\n",
            "Epoch 639/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 1.0626 - val_accuracy: 0.7396\n",
            "Epoch 640/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0231 - accuracy: 0.9948 - val_loss: 1.1414 - val_accuracy: 0.7188\n",
            "Epoch 641/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0310 - accuracy: 0.9935 - val_loss: 1.1796 - val_accuracy: 0.7083\n",
            "Epoch 642/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 1.0751 - val_accuracy: 0.7396\n",
            "Epoch 643/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 1.0749 - val_accuracy: 0.7396\n",
            "Epoch 644/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1096 - accuracy: 0.9961 - val_loss: 1.5280 - val_accuracy: 0.6667\n",
            "Epoch 645/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 0.9220 - val_accuracy: 0.7500\n",
            "Epoch 646/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0916 - accuracy: 0.9870 - val_loss: 0.7924 - val_accuracy: 0.7812\n",
            "Epoch 647/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0322 - accuracy: 0.9922 - val_loss: 0.9919 - val_accuracy: 0.7500\n",
            "Epoch 648/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0434 - accuracy: 0.9935 - val_loss: 0.9402 - val_accuracy: 0.7500\n",
            "Epoch 649/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0373 - accuracy: 0.9909 - val_loss: 1.0197 - val_accuracy: 0.7396\n",
            "Epoch 650/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0509 - accuracy: 0.9870 - val_loss: 1.0766 - val_accuracy: 0.7292\n",
            "Epoch 651/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.9394 - val_accuracy: 0.7604\n",
            "Epoch 652/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 1.0114 - val_accuracy: 0.7500\n",
            "Epoch 653/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0678 - accuracy: 0.9845 - val_loss: 1.1269 - val_accuracy: 0.7188\n",
            "Epoch 654/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0661 - accuracy: 0.9922 - val_loss: 1.0218 - val_accuracy: 0.7500\n",
            "Epoch 655/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1479 - accuracy: 0.9767 - val_loss: 1.0879 - val_accuracy: 0.7188\n",
            "Epoch 656/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0477 - accuracy: 0.9858 - val_loss: 1.1609 - val_accuracy: 0.7083\n",
            "Epoch 657/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 1.1613 - val_accuracy: 0.6979\n",
            "Epoch 658/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0603 - accuracy: 0.9870 - val_loss: 1.0498 - val_accuracy: 0.7396\n",
            "Epoch 659/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1906 - accuracy: 0.9845 - val_loss: 1.1229 - val_accuracy: 0.7500\n",
            "Epoch 660/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0368 - accuracy: 0.9896 - val_loss: 1.0686 - val_accuracy: 0.7292\n",
            "Epoch 661/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1532 - accuracy: 0.9922 - val_loss: 0.8783 - val_accuracy: 0.7292\n",
            "Epoch 662/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 1.0963 - val_accuracy: 0.7396\n",
            "Epoch 663/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0724 - accuracy: 0.9909 - val_loss: 1.5807 - val_accuracy: 0.6354\n",
            "Epoch 664/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0768 - accuracy: 0.9832 - val_loss: 1.0305 - val_accuracy: 0.7500\n",
            "Epoch 665/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0597 - accuracy: 0.9909 - val_loss: 0.9705 - val_accuracy: 0.7500\n",
            "Epoch 666/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0319 - accuracy: 0.9909 - val_loss: 1.0413 - val_accuracy: 0.7396\n",
            "Epoch 667/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1641 - accuracy: 0.9845 - val_loss: 0.9491 - val_accuracy: 0.7708\n",
            "Epoch 668/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0663 - accuracy: 0.9754 - val_loss: 1.0522 - val_accuracy: 0.7396\n",
            "Epoch 669/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 1.1983 - val_accuracy: 0.7188\n",
            "Epoch 670/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0327 - accuracy: 0.9935 - val_loss: 1.1731 - val_accuracy: 0.6979\n",
            "Epoch 671/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1353 - accuracy: 0.9909 - val_loss: 1.3785 - val_accuracy: 0.6979\n",
            "Epoch 672/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0593 - accuracy: 0.9858 - val_loss: 1.1876 - val_accuracy: 0.7083\n",
            "Epoch 673/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0302 - accuracy: 0.9883 - val_loss: 1.0458 - val_accuracy: 0.7396\n",
            "Epoch 674/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0357 - accuracy: 0.9961 - val_loss: 1.0424 - val_accuracy: 0.7292\n",
            "Epoch 675/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 1.1095 - val_accuracy: 0.7083\n",
            "Epoch 676/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0240 - accuracy: 0.9961 - val_loss: 1.1865 - val_accuracy: 0.7083\n",
            "Epoch 677/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0209 - accuracy: 0.9962 - val_loss: 1.1088 - val_accuracy: 0.7292\n",
            "Epoch 678/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0488 - accuracy: 0.9858 - val_loss: 1.0305 - val_accuracy: 0.7396\n",
            "Epoch 679/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0525 - accuracy: 0.9845 - val_loss: 0.9497 - val_accuracy: 0.7604\n",
            "Epoch 680/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0898 - accuracy: 0.9819 - val_loss: 1.0548 - val_accuracy: 0.7500\n",
            "Epoch 681/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0222 - accuracy: 0.9909 - val_loss: 0.9697 - val_accuracy: 0.7500\n",
            "Epoch 682/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 1.0495 - val_accuracy: 0.7188\n",
            "Epoch 683/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0511 - accuracy: 0.9870 - val_loss: 1.0614 - val_accuracy: 0.7188\n",
            "Epoch 684/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0491 - accuracy: 0.9858 - val_loss: 1.1699 - val_accuracy: 0.7188\n",
            "Epoch 685/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 1.0978 - val_accuracy: 0.7396\n",
            "Epoch 686/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 1.1353 - val_accuracy: 0.7292\n",
            "Epoch 687/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0394 - accuracy: 0.9909 - val_loss: 1.1314 - val_accuracy: 0.7292\n",
            "Epoch 688/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0160 - accuracy: 0.9987 - val_loss: 1.1121 - val_accuracy: 0.7500\n",
            "Epoch 689/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.9790 - val_accuracy: 0.7500\n",
            "Epoch 690/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.2066 - accuracy: 0.9909 - val_loss: 0.9873 - val_accuracy: 0.7500\n",
            "Epoch 691/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0585 - accuracy: 0.9858 - val_loss: 1.0309 - val_accuracy: 0.7292\n",
            "Epoch 692/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 1.1014 - val_accuracy: 0.7396\n",
            "Epoch 693/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0539 - accuracy: 0.9935 - val_loss: 0.8082 - val_accuracy: 0.7708\n",
            "Epoch 694/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 1.0747 - val_accuracy: 0.7396\n",
            "Epoch 695/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0492 - accuracy: 0.9909 - val_loss: 0.9607 - val_accuracy: 0.7292\n",
            "Epoch 696/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 1.0422 - val_accuracy: 0.7396\n",
            "Epoch 697/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 1.0204 - val_accuracy: 0.7500\n",
            "Epoch 698/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.8295 - val_accuracy: 0.7604\n",
            "Epoch 699/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0847 - accuracy: 0.9845 - val_loss: 1.2607 - val_accuracy: 0.7188\n",
            "Epoch 700/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0793 - accuracy: 0.9728 - val_loss: 0.9984 - val_accuracy: 0.7604\n",
            "Epoch 701/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0240 - accuracy: 0.9909 - val_loss: 1.0214 - val_accuracy: 0.7500\n",
            "Epoch 702/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 1.0798 - val_accuracy: 0.7292\n",
            "Epoch 703/1000\n",
            "25/25 [==============================] - 5s 211ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 1.0601 - val_accuracy: 0.7292\n",
            "Epoch 704/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.0649 - accuracy: 0.9883 - val_loss: 1.1766 - val_accuracy: 0.7188\n",
            "Epoch 705/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0924 - accuracy: 0.9858 - val_loss: 1.3110 - val_accuracy: 0.7188\n",
            "Epoch 706/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0367 - accuracy: 0.9870 - val_loss: 1.1129 - val_accuracy: 0.7292\n",
            "Epoch 707/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0552 - accuracy: 0.9845 - val_loss: 1.1481 - val_accuracy: 0.7188\n",
            "Epoch 708/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0637 - accuracy: 0.9870 - val_loss: 1.1277 - val_accuracy: 0.7292\n",
            "Epoch 709/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0743 - accuracy: 0.9883 - val_loss: 1.4599 - val_accuracy: 0.6979\n",
            "Epoch 710/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1427 - accuracy: 0.9793 - val_loss: 1.2891 - val_accuracy: 0.7292\n",
            "Epoch 711/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0217 - accuracy: 0.9922 - val_loss: 1.1929 - val_accuracy: 0.7188\n",
            "Epoch 712/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 1.0631 - val_accuracy: 0.7396\n",
            "Epoch 713/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0431 - accuracy: 0.9948 - val_loss: 1.0753 - val_accuracy: 0.7292\n",
            "Epoch 714/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0446 - accuracy: 0.9845 - val_loss: 1.0471 - val_accuracy: 0.7500\n",
            "Epoch 715/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 1.1023 - val_accuracy: 0.7292\n",
            "Epoch 716/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0262 - accuracy: 0.9948 - val_loss: 1.1209 - val_accuracy: 0.7188\n",
            "Epoch 717/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0248 - accuracy: 0.9948 - val_loss: 1.0667 - val_accuracy: 0.7396\n",
            "Epoch 718/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0554 - accuracy: 0.9883 - val_loss: 1.0411 - val_accuracy: 0.7396\n",
            "Epoch 719/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1088 - accuracy: 0.9845 - val_loss: 1.0134 - val_accuracy: 0.7500\n",
            "Epoch 720/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0500 - accuracy: 0.9858 - val_loss: 0.9337 - val_accuracy: 0.7396\n",
            "Epoch 721/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0626 - accuracy: 0.9883 - val_loss: 1.0155 - val_accuracy: 0.7396\n",
            "Epoch 722/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0392 - accuracy: 0.9909 - val_loss: 1.1034 - val_accuracy: 0.7292\n",
            "Epoch 723/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0198 - accuracy: 0.9961 - val_loss: 0.9389 - val_accuracy: 0.7708\n",
            "Epoch 724/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 0.9665 - val_accuracy: 0.7500\n",
            "Epoch 725/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0200 - accuracy: 0.9974 - val_loss: 1.0322 - val_accuracy: 0.7500\n",
            "Epoch 726/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0913 - accuracy: 0.9870 - val_loss: 1.0067 - val_accuracy: 0.7396\n",
            "Epoch 727/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0399 - accuracy: 0.9883 - val_loss: 0.9900 - val_accuracy: 0.7500\n",
            "Epoch 728/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0495 - accuracy: 0.9870 - val_loss: 0.9224 - val_accuracy: 0.7500\n",
            "Epoch 729/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.9328 - val_accuracy: 0.7500\n",
            "Epoch 730/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0303 - accuracy: 0.9883 - val_loss: 1.0691 - val_accuracy: 0.7292\n",
            "Epoch 731/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0728 - accuracy: 0.9767 - val_loss: 0.9181 - val_accuracy: 0.7708\n",
            "Epoch 732/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1140 - accuracy: 0.9806 - val_loss: 0.9965 - val_accuracy: 0.7604\n",
            "Epoch 733/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 1.0991 - val_accuracy: 0.7396\n",
            "Epoch 734/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0301 - accuracy: 0.9922 - val_loss: 0.9793 - val_accuracy: 0.7500\n",
            "Epoch 735/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1088 - accuracy: 0.9845 - val_loss: 0.8843 - val_accuracy: 0.7812\n",
            "Epoch 736/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0264 - accuracy: 0.9935 - val_loss: 0.9484 - val_accuracy: 0.7604\n",
            "Epoch 737/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0446 - accuracy: 0.9922 - val_loss: 1.3528 - val_accuracy: 0.6875\n",
            "Epoch 738/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0198 - accuracy: 0.9961 - val_loss: 1.2855 - val_accuracy: 0.7188\n",
            "Epoch 739/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0319 - accuracy: 0.9948 - val_loss: 1.2179 - val_accuracy: 0.6979\n",
            "Epoch 740/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0488 - accuracy: 0.9896 - val_loss: 1.5720 - val_accuracy: 0.6771\n",
            "Epoch 741/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0774 - accuracy: 0.9767 - val_loss: 1.0063 - val_accuracy: 0.7396\n",
            "Epoch 742/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0202 - accuracy: 0.9961 - val_loss: 0.9734 - val_accuracy: 0.7604\n",
            "Epoch 743/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.1061 - accuracy: 0.9793 - val_loss: 1.7140 - val_accuracy: 0.5938\n",
            "Epoch 744/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1704 - accuracy: 0.9806 - val_loss: 0.7625 - val_accuracy: 0.8021\n",
            "Epoch 745/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1059 - accuracy: 0.9754 - val_loss: 1.3450 - val_accuracy: 0.6979\n",
            "Epoch 746/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1687 - accuracy: 0.9845 - val_loss: 1.8331 - val_accuracy: 0.5833\n",
            "Epoch 747/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1393 - accuracy: 0.9741 - val_loss: 0.7972 - val_accuracy: 0.7917\n",
            "Epoch 748/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1105 - accuracy: 0.9715 - val_loss: 0.6890 - val_accuracy: 0.8021\n",
            "Epoch 749/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.8060 - val_accuracy: 0.7708\n",
            "Epoch 750/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0245 - accuracy: 0.9961 - val_loss: 1.0219 - val_accuracy: 0.7396\n",
            "Epoch 751/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 1.0322 - val_accuracy: 0.7292\n",
            "Epoch 752/1000\n",
            "25/25 [==============================] - 5s 210ms/step - loss: 0.0602 - accuracy: 0.9961 - val_loss: 1.0220 - val_accuracy: 0.7500\n",
            "Epoch 753/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0892 - accuracy: 0.9845 - val_loss: 0.9994 - val_accuracy: 0.7604\n",
            "Epoch 754/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0379 - accuracy: 0.9896 - val_loss: 1.0706 - val_accuracy: 0.7396\n",
            "Epoch 755/1000\n",
            "25/25 [==============================] - 5s 211ms/step - loss: 0.0223 - accuracy: 0.9975 - val_loss: 0.9618 - val_accuracy: 0.7604\n",
            "Epoch 756/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.1645 - accuracy: 0.9870 - val_loss: 0.9774 - val_accuracy: 0.7396\n",
            "Epoch 757/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0705 - accuracy: 0.9870 - val_loss: 1.1174 - val_accuracy: 0.7292\n",
            "Epoch 758/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0277 - accuracy: 0.9948 - val_loss: 0.9999 - val_accuracy: 0.7396\n",
            "Epoch 759/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0311 - accuracy: 0.9935 - val_loss: 0.9018 - val_accuracy: 0.7604\n",
            "Epoch 760/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0594 - accuracy: 0.9948 - val_loss: 1.2231 - val_accuracy: 0.7188\n",
            "Epoch 761/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1566 - accuracy: 0.9754 - val_loss: 1.2965 - val_accuracy: 0.7083\n",
            "Epoch 762/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0417 - accuracy: 0.9922 - val_loss: 1.0617 - val_accuracy: 0.7396\n",
            "Epoch 763/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.1185 - accuracy: 0.9858 - val_loss: 1.3092 - val_accuracy: 0.6979\n",
            "Epoch 764/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0759 - accuracy: 0.9832 - val_loss: 0.9238 - val_accuracy: 0.7396\n",
            "Epoch 765/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0841 - accuracy: 0.9832 - val_loss: 0.8986 - val_accuracy: 0.7500\n",
            "Epoch 766/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0570 - accuracy: 0.9806 - val_loss: 1.2347 - val_accuracy: 0.6979\n",
            "Epoch 767/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 1.1230 - val_accuracy: 0.7396\n",
            "Epoch 768/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.1854 - accuracy: 0.9845 - val_loss: 1.1943 - val_accuracy: 0.7396\n",
            "Epoch 769/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0767 - accuracy: 0.9870 - val_loss: 1.1949 - val_accuracy: 0.7292\n",
            "Epoch 770/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0300 - accuracy: 0.9870 - val_loss: 1.0558 - val_accuracy: 0.7292\n",
            "Epoch 771/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0422 - accuracy: 0.9896 - val_loss: 1.2053 - val_accuracy: 0.7083\n",
            "Epoch 772/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 1.0236 - val_accuracy: 0.7396\n",
            "Epoch 773/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0347 - accuracy: 0.9948 - val_loss: 0.9382 - val_accuracy: 0.7812\n",
            "Epoch 774/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0919 - accuracy: 0.9883 - val_loss: 0.9619 - val_accuracy: 0.7292\n",
            "Epoch 775/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.1017 - accuracy: 0.9534 - val_loss: 1.1306 - val_accuracy: 0.7188\n",
            "Epoch 776/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0360 - accuracy: 0.9858 - val_loss: 1.3251 - val_accuracy: 0.7083\n",
            "Epoch 777/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0272 - accuracy: 0.9961 - val_loss: 1.0456 - val_accuracy: 0.7292\n",
            "Epoch 778/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.9298 - val_accuracy: 0.7500\n",
            "Epoch 779/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.1450 - accuracy: 0.9909 - val_loss: 0.9215 - val_accuracy: 0.7604\n",
            "Epoch 780/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0769 - accuracy: 0.9728 - val_loss: 1.0351 - val_accuracy: 0.7500\n",
            "Epoch 781/1000\n",
            "25/25 [==============================] - 5s 214ms/step - loss: 0.0249 - accuracy: 0.9950 - val_loss: 1.1320 - val_accuracy: 0.7292\n",
            "Epoch 782/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0475 - accuracy: 0.9845 - val_loss: 1.1769 - val_accuracy: 0.7292\n",
            "Epoch 783/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0676 - accuracy: 0.9845 - val_loss: 0.8270 - val_accuracy: 0.7708\n",
            "Epoch 784/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 0.8987 - val_accuracy: 0.7604\n",
            "Epoch 785/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0207 - accuracy: 0.9922 - val_loss: 0.9937 - val_accuracy: 0.7396\n",
            "Epoch 786/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0244 - accuracy: 0.9974 - val_loss: 0.9760 - val_accuracy: 0.7708\n",
            "Epoch 787/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 1.0820 - val_accuracy: 0.7396\n",
            "Epoch 788/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1271 - accuracy: 0.9780 - val_loss: 1.0525 - val_accuracy: 0.7396\n",
            "Epoch 789/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0375 - accuracy: 0.9948 - val_loss: 0.9757 - val_accuracy: 0.7500\n",
            "Epoch 790/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0858 - accuracy: 0.9832 - val_loss: 1.3008 - val_accuracy: 0.7083\n",
            "Epoch 791/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0258 - accuracy: 0.9922 - val_loss: 1.0558 - val_accuracy: 0.7500\n",
            "Epoch 792/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.9313 - val_accuracy: 0.7604\n",
            "Epoch 793/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0546 - accuracy: 0.9896 - val_loss: 0.8474 - val_accuracy: 0.7812\n",
            "Epoch 794/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0374 - accuracy: 0.9922 - val_loss: 1.1435 - val_accuracy: 0.7188\n",
            "Epoch 795/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0296 - accuracy: 0.9870 - val_loss: 0.9642 - val_accuracy: 0.7708\n",
            "Epoch 796/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0165 - accuracy: 0.9974 - val_loss: 0.9948 - val_accuracy: 0.7500\n",
            "Epoch 797/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0469 - accuracy: 0.9922 - val_loss: 0.8288 - val_accuracy: 0.7708\n",
            "Epoch 798/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0295 - accuracy: 0.9883 - val_loss: 0.8964 - val_accuracy: 0.7604\n",
            "Epoch 799/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0585 - accuracy: 0.9922 - val_loss: 0.8757 - val_accuracy: 0.7500\n",
            "Epoch 800/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0945 - accuracy: 0.9741 - val_loss: 1.2598 - val_accuracy: 0.7083\n",
            "Epoch 801/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 1.1821 - val_accuracy: 0.7292\n",
            "Epoch 802/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0691 - accuracy: 0.9935 - val_loss: 0.9423 - val_accuracy: 0.7604\n",
            "Epoch 803/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0370 - accuracy: 0.9922 - val_loss: 1.0332 - val_accuracy: 0.7396\n",
            "Epoch 804/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0229 - accuracy: 0.9948 - val_loss: 1.0982 - val_accuracy: 0.7396\n",
            "Epoch 805/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0164 - accuracy: 0.9961 - val_loss: 1.0501 - val_accuracy: 0.7396\n",
            "Epoch 806/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0319 - accuracy: 0.9935 - val_loss: 0.9555 - val_accuracy: 0.7604\n",
            "Epoch 807/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.9361 - val_accuracy: 0.7708\n",
            "Epoch 808/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.9459 - val_accuracy: 0.7604\n",
            "Epoch 809/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.9648 - val_accuracy: 0.7500\n",
            "Epoch 810/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0554 - accuracy: 0.9896 - val_loss: 1.0426 - val_accuracy: 0.7292\n",
            "Epoch 811/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0835 - accuracy: 0.9883 - val_loss: 1.4238 - val_accuracy: 0.6458\n",
            "Epoch 812/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0703 - accuracy: 0.9780 - val_loss: 1.2686 - val_accuracy: 0.7083\n",
            "Epoch 813/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0961 - accuracy: 0.9896 - val_loss: 0.9375 - val_accuracy: 0.7604\n",
            "Epoch 814/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0771 - accuracy: 0.9845 - val_loss: 1.2602 - val_accuracy: 0.7188\n",
            "Epoch 815/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0317 - accuracy: 0.9935 - val_loss: 1.1227 - val_accuracy: 0.7396\n",
            "Epoch 816/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0484 - accuracy: 0.9948 - val_loss: 0.9499 - val_accuracy: 0.7812\n",
            "Epoch 817/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0485 - accuracy: 0.9858 - val_loss: 1.3416 - val_accuracy: 0.6979\n",
            "Epoch 818/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 1.2724 - val_accuracy: 0.7188\n",
            "Epoch 819/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0596 - accuracy: 0.9935 - val_loss: 0.8932 - val_accuracy: 0.7604\n",
            "Epoch 820/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0374 - accuracy: 0.9896 - val_loss: 1.0683 - val_accuracy: 0.7292\n",
            "Epoch 821/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0232 - accuracy: 0.9948 - val_loss: 1.0579 - val_accuracy: 0.7292\n",
            "Epoch 822/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0750 - accuracy: 0.9909 - val_loss: 1.1187 - val_accuracy: 0.7188\n",
            "Epoch 823/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0942 - accuracy: 0.9819 - val_loss: 0.7707 - val_accuracy: 0.7917\n",
            "Epoch 824/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0310 - accuracy: 0.9883 - val_loss: 0.8148 - val_accuracy: 0.7708\n",
            "Epoch 825/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.1026 - accuracy: 0.9961 - val_loss: 0.8748 - val_accuracy: 0.7604\n",
            "Epoch 826/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.9206 - val_accuracy: 0.7604\n",
            "Epoch 827/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0520 - accuracy: 0.9922 - val_loss: 0.9638 - val_accuracy: 0.7708\n",
            "Epoch 828/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0573 - accuracy: 0.9922 - val_loss: 0.9241 - val_accuracy: 0.7812\n",
            "Epoch 829/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.9183 - val_accuracy: 0.7500\n",
            "Epoch 830/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 1.1772 - val_accuracy: 0.7396\n",
            "Epoch 831/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 1.1611 - val_accuracy: 0.7396\n",
            "Epoch 832/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1339 - accuracy: 0.9922 - val_loss: 1.2272 - val_accuracy: 0.7083\n",
            "Epoch 833/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0742 - accuracy: 0.9737 - val_loss: 1.6061 - val_accuracy: 0.6667\n",
            "Epoch 834/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1268 - accuracy: 0.9793 - val_loss: 1.3190 - val_accuracy: 0.6979\n",
            "Epoch 835/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 1.1152 - val_accuracy: 0.7396\n",
            "Epoch 836/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0805 - accuracy: 0.9896 - val_loss: 1.3848 - val_accuracy: 0.6771\n",
            "Epoch 837/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.1092 - accuracy: 0.9858 - val_loss: 1.2965 - val_accuracy: 0.7083\n",
            "Epoch 838/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.2407 - accuracy: 0.9780 - val_loss: 0.8920 - val_accuracy: 0.7604\n",
            "Epoch 839/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0804 - accuracy: 0.9806 - val_loss: 0.9612 - val_accuracy: 0.7708\n",
            "Epoch 840/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0475 - accuracy: 0.9883 - val_loss: 1.0142 - val_accuracy: 0.7292\n",
            "Epoch 841/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 1.0163 - val_accuracy: 0.7396\n",
            "Epoch 842/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0456 - accuracy: 0.9948 - val_loss: 1.3502 - val_accuracy: 0.6458\n",
            "Epoch 843/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 1.1690 - val_accuracy: 0.7396\n",
            "Epoch 844/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0296 - accuracy: 0.9883 - val_loss: 1.1710 - val_accuracy: 0.7292\n",
            "Epoch 845/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.1113 - accuracy: 0.9974 - val_loss: 1.0342 - val_accuracy: 0.7292\n",
            "Epoch 846/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0620 - accuracy: 0.9845 - val_loss: 0.8449 - val_accuracy: 0.7604\n",
            "Epoch 847/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 1.0066 - val_accuracy: 0.7500\n",
            "Epoch 848/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 1.0060 - val_accuracy: 0.7604\n",
            "Epoch 849/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0782 - accuracy: 0.9922 - val_loss: 0.8164 - val_accuracy: 0.7708\n",
            "Epoch 850/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0624 - accuracy: 0.9896 - val_loss: 1.1562 - val_accuracy: 0.7188\n",
            "Epoch 851/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1974 - accuracy: 0.9909 - val_loss: 0.9850 - val_accuracy: 0.7396\n",
            "Epoch 852/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0446 - accuracy: 0.9858 - val_loss: 1.0216 - val_accuracy: 0.7396\n",
            "Epoch 853/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 1.0846 - val_accuracy: 0.7396\n",
            "Epoch 854/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0229 - accuracy: 0.9961 - val_loss: 0.9030 - val_accuracy: 0.7604\n",
            "Epoch 855/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0251 - accuracy: 0.9961 - val_loss: 1.1015 - val_accuracy: 0.7292\n",
            "Epoch 856/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 1.2017 - val_accuracy: 0.7188\n",
            "Epoch 857/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0233 - accuracy: 0.9961 - val_loss: 0.9049 - val_accuracy: 0.7708\n",
            "Epoch 858/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0274 - accuracy: 0.9948 - val_loss: 1.0312 - val_accuracy: 0.7396\n",
            "Epoch 859/1000\n",
            "25/25 [==============================] - 5s 205ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 1.0756 - val_accuracy: 0.7396\n",
            "Epoch 860/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0255 - accuracy: 0.9948 - val_loss: 1.0099 - val_accuracy: 0.7292\n",
            "Epoch 861/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0280 - accuracy: 0.9935 - val_loss: 1.1423 - val_accuracy: 0.7188\n",
            "Epoch 862/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1020 - accuracy: 0.9767 - val_loss: 1.3171 - val_accuracy: 0.6667\n",
            "Epoch 863/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.1215 - accuracy: 0.9922 - val_loss: 1.3248 - val_accuracy: 0.7188\n",
            "Epoch 864/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1509 - accuracy: 0.9845 - val_loss: 1.4018 - val_accuracy: 0.6250\n",
            "Epoch 865/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0403 - accuracy: 0.9896 - val_loss: 1.0157 - val_accuracy: 0.7500\n",
            "Epoch 866/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 1.0400 - val_accuracy: 0.7500\n",
            "Epoch 867/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 1.0487 - val_accuracy: 0.7292\n",
            "Epoch 868/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0570 - accuracy: 0.9896 - val_loss: 0.9662 - val_accuracy: 0.7500\n",
            "Epoch 869/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0498 - accuracy: 0.9922 - val_loss: 0.9658 - val_accuracy: 0.7396\n",
            "Epoch 870/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1023 - accuracy: 0.9961 - val_loss: 1.1081 - val_accuracy: 0.7292\n",
            "Epoch 871/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0381 - accuracy: 0.9896 - val_loss: 0.9202 - val_accuracy: 0.7708\n",
            "Epoch 872/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0738 - accuracy: 0.9935 - val_loss: 0.9291 - val_accuracy: 0.7708\n",
            "Epoch 873/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0835 - accuracy: 0.9806 - val_loss: 1.1832 - val_accuracy: 0.7188\n",
            "Epoch 874/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0559 - accuracy: 0.9896 - val_loss: 1.0736 - val_accuracy: 0.7188\n",
            "Epoch 875/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0847 - accuracy: 0.9974 - val_loss: 0.9880 - val_accuracy: 0.7604\n",
            "Epoch 876/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0342 - accuracy: 0.9922 - val_loss: 1.0210 - val_accuracy: 0.7292\n",
            "Epoch 877/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0191 - accuracy: 0.9961 - val_loss: 0.9147 - val_accuracy: 0.7604\n",
            "Epoch 878/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 0.9213 - val_accuracy: 0.7500\n",
            "Epoch 879/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0418 - accuracy: 0.9909 - val_loss: 1.1102 - val_accuracy: 0.7188\n",
            "Epoch 880/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 1.0281 - val_accuracy: 0.7604\n",
            "Epoch 881/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 1.0164 - val_accuracy: 0.7292\n",
            "Epoch 882/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0889 - accuracy: 0.9883 - val_loss: 1.2377 - val_accuracy: 0.7188\n",
            "Epoch 883/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0586 - accuracy: 0.9819 - val_loss: 1.3566 - val_accuracy: 0.6875\n",
            "Epoch 884/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0717 - accuracy: 0.9909 - val_loss: 1.1855 - val_accuracy: 0.7188\n",
            "Epoch 885/1000\n",
            "25/25 [==============================] - 5s 207ms/step - loss: 0.0328 - accuracy: 0.9875 - val_loss: 1.0450 - val_accuracy: 0.7708\n",
            "Epoch 886/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0120 - accuracy: 0.9987 - val_loss: 1.0605 - val_accuracy: 0.7396\n",
            "Epoch 887/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0359 - accuracy: 0.9922 - val_loss: 0.9719 - val_accuracy: 0.7396\n",
            "Epoch 888/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1597 - accuracy: 0.9832 - val_loss: 0.8323 - val_accuracy: 0.7708\n",
            "Epoch 889/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0196 - accuracy: 0.9974 - val_loss: 1.0571 - val_accuracy: 0.7396\n",
            "Epoch 890/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 1.0736 - val_accuracy: 0.7292\n",
            "Epoch 891/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 1.1581 - val_accuracy: 0.7396\n",
            "Epoch 892/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0945 - accuracy: 0.9922 - val_loss: 1.1067 - val_accuracy: 0.7292\n",
            "Epoch 893/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1088 - accuracy: 0.9845 - val_loss: 0.9284 - val_accuracy: 0.7500\n",
            "Epoch 894/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0507 - accuracy: 0.9922 - val_loss: 1.0444 - val_accuracy: 0.7500\n",
            "Epoch 895/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0484 - accuracy: 0.9922 - val_loss: 0.9739 - val_accuracy: 0.7500\n",
            "Epoch 896/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: 0.8201 - val_accuracy: 0.7708\n",
            "Epoch 897/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0492 - accuracy: 0.9896 - val_loss: 1.2464 - val_accuracy: 0.7188\n",
            "Epoch 898/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0599 - accuracy: 0.9806 - val_loss: 0.8675 - val_accuracy: 0.7604\n",
            "Epoch 899/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0293 - accuracy: 0.9948 - val_loss: 1.0061 - val_accuracy: 0.7500\n",
            "Epoch 900/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1188 - accuracy: 0.9883 - val_loss: 1.5919 - val_accuracy: 0.6458\n",
            "Epoch 901/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 1.2110 - val_accuracy: 0.7188\n",
            "Epoch 902/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1695 - accuracy: 0.9780 - val_loss: 0.8550 - val_accuracy: 0.7188\n",
            "Epoch 903/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0690 - accuracy: 0.9780 - val_loss: 1.0664 - val_accuracy: 0.7396\n",
            "Epoch 904/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0485 - accuracy: 0.9909 - val_loss: 1.2560 - val_accuracy: 0.6979\n",
            "Epoch 905/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 1.0978 - val_accuracy: 0.7500\n",
            "Epoch 906/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.9669 - val_accuracy: 0.7604\n",
            "Epoch 907/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 1.0427 - val_accuracy: 0.7604\n",
            "Epoch 908/1000\n",
            "25/25 [==============================] - 5s 203ms/step - loss: 0.0300 - accuracy: 0.9948 - val_loss: 1.0560 - val_accuracy: 0.7396\n",
            "Epoch 909/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 1.1806 - val_accuracy: 0.7292\n",
            "Epoch 910/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0832 - accuracy: 0.9948 - val_loss: 1.1054 - val_accuracy: 0.7396\n",
            "Epoch 911/1000\n",
            "25/25 [==============================] - 5s 211ms/step - loss: 0.0268 - accuracy: 0.9925 - val_loss: 0.9657 - val_accuracy: 0.7500\n",
            "Epoch 912/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.0193 - accuracy: 0.9961 - val_loss: 1.0634 - val_accuracy: 0.7396\n",
            "Epoch 913/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.9675 - val_accuracy: 0.7500\n",
            "Epoch 914/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1134 - accuracy: 0.9806 - val_loss: 1.1196 - val_accuracy: 0.7188\n",
            "Epoch 915/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0281 - accuracy: 0.9883 - val_loss: 0.8260 - val_accuracy: 0.7708\n",
            "Epoch 916/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.2574 - accuracy: 0.9728 - val_loss: 1.8737 - val_accuracy: 0.5729\n",
            "Epoch 917/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.1122 - accuracy: 0.9702 - val_loss: 1.2366 - val_accuracy: 0.6979\n",
            "Epoch 918/1000\n",
            "25/25 [==============================] - 5s 200ms/step - loss: 0.2134 - accuracy: 0.9780 - val_loss: 1.7040 - val_accuracy: 0.6042\n",
            "Epoch 919/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 1.3316 - val_accuracy: 0.7188\n",
            "Epoch 920/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0395 - accuracy: 0.9948 - val_loss: 1.2339 - val_accuracy: 0.7292\n",
            "Epoch 921/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0341 - accuracy: 0.9896 - val_loss: 1.0678 - val_accuracy: 0.7500\n",
            "Epoch 922/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0695 - accuracy: 0.9870 - val_loss: 0.9809 - val_accuracy: 0.7396\n",
            "Epoch 923/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0290 - accuracy: 0.9922 - val_loss: 1.0523 - val_accuracy: 0.7604\n",
            "Epoch 924/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0135 - accuracy: 0.9987 - val_loss: 1.1948 - val_accuracy: 0.7292\n",
            "Epoch 925/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0933 - accuracy: 0.9909 - val_loss: 1.3085 - val_accuracy: 0.6458\n",
            "Epoch 926/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0498 - accuracy: 0.9858 - val_loss: 1.2103 - val_accuracy: 0.7188\n",
            "Epoch 927/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0618 - accuracy: 0.9858 - val_loss: 1.2816 - val_accuracy: 0.6875\n",
            "Epoch 928/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.2093 - accuracy: 0.9741 - val_loss: 0.8858 - val_accuracy: 0.7708\n",
            "Epoch 929/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 1.0416 - val_accuracy: 0.7500\n",
            "Epoch 930/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0343 - accuracy: 0.9961 - val_loss: 1.0397 - val_accuracy: 0.7292\n",
            "Epoch 931/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0169 - accuracy: 0.9961 - val_loss: 1.0385 - val_accuracy: 0.7396\n",
            "Epoch 932/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0468 - accuracy: 0.9922 - val_loss: 1.1550 - val_accuracy: 0.7396\n",
            "Epoch 933/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0251 - accuracy: 0.9948 - val_loss: 1.3193 - val_accuracy: 0.7292\n",
            "Epoch 934/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 1.1360 - val_accuracy: 0.7292\n",
            "Epoch 935/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0222 - accuracy: 0.9935 - val_loss: 1.1423 - val_accuracy: 0.7292\n",
            "Epoch 936/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0301 - accuracy: 0.9974 - val_loss: 1.1124 - val_accuracy: 0.7500\n",
            "Epoch 937/1000\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 1.0181 - val_accuracy: 0.7292\n",
            "Epoch 938/1000\n",
            "25/25 [==============================] - 5s 204ms/step - loss: 0.0962 - accuracy: 0.9870 - val_loss: 0.7508 - val_accuracy: 0.7708\n",
            "Epoch 939/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.3187 - accuracy: 0.9780 - val_loss: 1.3482 - val_accuracy: 0.6979\n",
            "Epoch 940/1000\n",
            "25/25 [==============================] - 5s 202ms/step - loss: 0.0403 - accuracy: 0.9961 - val_loss: 1.0235 - val_accuracy: 0.7500\n",
            "Epoch 941/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.0804 - accuracy: 0.9974 - val_loss: 1.2325 - val_accuracy: 0.7292\n",
            "Epoch 942/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0804 - accuracy: 0.9832 - val_loss: 1.3686 - val_accuracy: 0.6979\n",
            "Epoch 943/1000\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0688 - accuracy: 0.9922 - val_loss: 1.0266 - val_accuracy: 0.7396\n",
            "Epoch 944/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 1.0903 - val_accuracy: 0.7292\n",
            "Epoch 945/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 1.0593 - val_accuracy: 0.7292\n",
            "Epoch 946/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0414 - accuracy: 0.9922 - val_loss: 1.1161 - val_accuracy: 0.7188\n",
            "Epoch 947/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0205 - accuracy: 0.9922 - val_loss: 1.1054 - val_accuracy: 0.7500\n",
            "Epoch 948/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0166 - accuracy: 0.9961 - val_loss: 1.0896 - val_accuracy: 0.7396\n",
            "Epoch 949/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0127 - accuracy: 0.9987 - val_loss: 0.9851 - val_accuracy: 0.7604\n",
            "Epoch 950/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0732 - accuracy: 0.9909 - val_loss: 1.2318 - val_accuracy: 0.7083\n",
            "Epoch 951/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.0350 - accuracy: 0.9922 - val_loss: 1.0215 - val_accuracy: 0.7396\n",
            "Epoch 952/1000\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.0454 - accuracy: 0.9896 - val_loss: 0.9118 - val_accuracy: 0.7708\n",
            "Epoch 953/1000\n",
            "25/25 [==============================] - 5s 198ms/step - loss: 0.0777 - accuracy: 0.9922 - val_loss: 1.5565 - val_accuracy: 0.6250\n",
            "Epoch 954/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0385 - accuracy: 0.9909 - val_loss: 1.3283 - val_accuracy: 0.6875\n",
            "Epoch 955/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0288 - accuracy: 0.9935 - val_loss: 1.2967 - val_accuracy: 0.6979\n",
            "Epoch 956/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.0500 - accuracy: 0.9948 - val_loss: 1.0915 - val_accuracy: 0.7500\n",
            "Epoch 957/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1193 - accuracy: 0.9883 - val_loss: 0.9855 - val_accuracy: 0.7292\n",
            "Epoch 958/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0842 - accuracy: 0.9767 - val_loss: 0.9417 - val_accuracy: 0.7604\n",
            "Epoch 959/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0323 - accuracy: 0.9935 - val_loss: 1.0644 - val_accuracy: 0.7604\n",
            "Epoch 960/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1096 - accuracy: 0.9948 - val_loss: 0.9725 - val_accuracy: 0.7604\n",
            "Epoch 961/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.9650 - val_accuracy: 0.7604\n",
            "Epoch 962/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0422 - accuracy: 0.9922 - val_loss: 1.0169 - val_accuracy: 0.7500\n",
            "Epoch 963/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0297 - accuracy: 0.9887 - val_loss: 1.2121 - val_accuracy: 0.7292\n",
            "Epoch 964/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0212 - accuracy: 0.9974 - val_loss: 0.9322 - val_accuracy: 0.7708\n",
            "Epoch 965/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.2136 - accuracy: 0.9858 - val_loss: 1.3168 - val_accuracy: 0.7292\n",
            "Epoch 966/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0265 - accuracy: 0.9922 - val_loss: 1.0330 - val_accuracy: 0.7396\n",
            "Epoch 967/1000\n",
            "25/25 [==============================] - 5s 191ms/step - loss: 0.1089 - accuracy: 0.9806 - val_loss: 0.8274 - val_accuracy: 0.7917\n",
            "Epoch 968/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.2341 - accuracy: 0.9870 - val_loss: 0.9169 - val_accuracy: 0.7500\n",
            "Epoch 969/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.0650 - accuracy: 0.9896 - val_loss: 1.3294 - val_accuracy: 0.7083\n",
            "Epoch 970/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 1.2810 - val_accuracy: 0.7188\n",
            "Epoch 971/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0525 - accuracy: 0.9909 - val_loss: 1.2498 - val_accuracy: 0.7292\n",
            "Epoch 972/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0580 - accuracy: 0.9858 - val_loss: 1.0493 - val_accuracy: 0.7292\n",
            "Epoch 973/1000\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 1.0083 - val_accuracy: 0.7500\n",
            "Epoch 974/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.1516 - accuracy: 0.9832 - val_loss: 1.3734 - val_accuracy: 0.6354\n",
            "Epoch 975/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0252 - accuracy: 0.9961 - val_loss: 1.1517 - val_accuracy: 0.7083\n",
            "Epoch 976/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 1.0873 - val_accuracy: 0.7396\n",
            "Epoch 977/1000\n",
            "25/25 [==============================] - 5s 199ms/step - loss: 0.1395 - accuracy: 0.9896 - val_loss: 0.7124 - val_accuracy: 0.7917\n",
            "Epoch 978/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.9025 - val_accuracy: 0.7500\n",
            "Epoch 979/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.1350 - accuracy: 0.9858 - val_loss: 1.0148 - val_accuracy: 0.7292\n",
            "Epoch 980/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.0796 - accuracy: 0.9896 - val_loss: 1.2698 - val_accuracy: 0.6771\n",
            "Epoch 981/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0869 - accuracy: 0.9832 - val_loss: 0.8572 - val_accuracy: 0.7604\n",
            "Epoch 982/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.2117 - accuracy: 0.9909 - val_loss: 1.1217 - val_accuracy: 0.7396\n",
            "Epoch 983/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.1312 - accuracy: 0.9870 - val_loss: 1.0374 - val_accuracy: 0.7500\n",
            "Epoch 984/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0867 - accuracy: 0.9806 - val_loss: 0.9152 - val_accuracy: 0.7708\n",
            "Epoch 985/1000\n",
            "25/25 [==============================] - 5s 186ms/step - loss: 0.0179 - accuracy: 0.9974 - val_loss: 1.0329 - val_accuracy: 0.7292\n",
            "Epoch 986/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.1243 - accuracy: 0.9858 - val_loss: 0.8560 - val_accuracy: 0.7604\n",
            "Epoch 987/1000\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 0.1053 - accuracy: 0.9741 - val_loss: 0.9665 - val_accuracy: 0.7604\n",
            "Epoch 988/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 1.2288 - val_accuracy: 0.6979\n",
            "Epoch 989/1000\n",
            "25/25 [==============================] - 5s 201ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 1.0676 - val_accuracy: 0.7500\n",
            "Epoch 990/1000\n",
            "25/25 [==============================] - 5s 197ms/step - loss: 0.0466 - accuracy: 0.9896 - val_loss: 1.0037 - val_accuracy: 0.7396\n",
            "Epoch 991/1000\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 0.0481 - accuracy: 0.9909 - val_loss: 0.9198 - val_accuracy: 0.7500\n",
            "Epoch 992/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0181 - accuracy: 0.9961 - val_loss: 1.0246 - val_accuracy: 0.7500\n",
            "Epoch 993/1000\n",
            "25/25 [==============================] - 5s 187ms/step - loss: 0.0218 - accuracy: 0.9987 - val_loss: 1.0950 - val_accuracy: 0.7292\n",
            "Epoch 994/1000\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.0362 - accuracy: 0.9935 - val_loss: 1.2143 - val_accuracy: 0.7292\n",
            "Epoch 995/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0267 - accuracy: 0.9935 - val_loss: 1.2766 - val_accuracy: 0.7083\n",
            "Epoch 996/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 1.1294 - val_accuracy: 0.7500\n",
            "Epoch 997/1000\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0783 - accuracy: 0.9909 - val_loss: 1.0264 - val_accuracy: 0.7500\n",
            "Epoch 998/1000\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 0.0865 - accuracy: 0.9858 - val_loss: 1.1071 - val_accuracy: 0.7396\n",
            "Epoch 999/1000\n",
            "25/25 [==============================] - 5s 188ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 1.1321 - val_accuracy: 0.7292\n",
            "Epoch 1000/1000\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.0918 - accuracy: 0.9922 - val_loss: 0.7097 - val_accuracy: 0.7812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOhKovWrbmOt",
        "colab_type": "code",
        "outputId": "1f354ffe-d178-4ac1-d5fc-c420b8596cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.ylim(0.3, 1.1)\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.ylim(0,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0KOIhBX8n7U",
        "colab_type": "code",
        "outputId": "a5a919b0-75c8-4868-a99a-7a738bd94f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "for x, y in test_data.repeat(1):\n",
        "    x_data.append(x)\n",
        "    y_data.append(y)\n",
        "\n",
        "x_data = np.vstack(x_data).reshape(-1,224,224,3)\n",
        "predictions = model.predict_classes(x_data)\n",
        "\n",
        "for i in range(len(y_data)):\n",
        "    print(y_data[i], predictions[i], 'x' if list(y_data[i]).index(1) == predictions[i] else '' )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 1 x\n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 1 x\n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 2 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 1 x\n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 1 x\n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 1 x\n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 1 x\n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 2 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 2 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 4 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 2 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 4 \n",
            "tf.Tensor([0. 1. 0. 0. 0.], shape=(5,), dtype=float32) 1 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 4 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 3 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 4 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 3 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 4 \n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 1. 0. 0.], shape=(5,), dtype=float32) 2 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 2 \n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 0. 1.], shape=(5,), dtype=float32) 4 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 4 \n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 2 \n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 0 \n",
            "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32) 3 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 2 \n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n",
            "tf.Tensor([1. 0. 0. 0. 0.], shape=(5,), dtype=float32) 0 x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAdQCVhwaJBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('drive/My Drive/Colab Notebooks/grocery/grocery-categories-v06-b.h5')\n",
        "model.save_weights('drive/My Drive/Colab Notebooks/grocery/grocery-categories-v06-b.weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHWvwkCpDH_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}